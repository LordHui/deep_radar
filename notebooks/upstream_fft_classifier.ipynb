{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_fft_model(hidden_1,\n",
    "                         dense_1,\n",
    "                         kernel_initializer='normal',\n",
    "                         dropout=None,\n",
    "                         optimizer=None,\n",
    "                         input_shape=(5, 256)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_1, return_sequences=False, input_shape=input_shape, name='lstm_1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(dense_1, activation='relu', name='dense_1'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_humans_nonhumans(data_dir, humans=None, nonhumans=None):\n",
    "    \n",
    "    nonhumans_path = os.path.join(data_dir, 'Data_win_fft_Nonhuman.npy')\n",
    "    humans_path = os.path.join(data_dir, 'Data_win_fft_Human.npy')\n",
    "    n_nonhumans = np.load(nonhumans_path, allow_pickle=True)\n",
    "    n_humans = np.load(humans_path, allow_pickle=True) \n",
    "    \n",
    "    humans = np.vstack((humans, n_humans)) if humans is not None else n_humans\n",
    "    nonhumans = np.vstack((nonhumans, n_nonhumans)) if nonhumans is not None else n_nonhumans\n",
    "        \n",
    "    labels = [1 for i in range(len(humans))]\n",
    "    labels += [0 for i in range(len(nonhumans))]\n",
    "        \n",
    "    return humans, nonhumans, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upstream_data(radar_type, scaling=True):\n",
    "    \n",
    "    data_dir = '/scratch/sk7898/deep_radar/data/classification'\n",
    "\n",
    "    if radar_type:\n",
    "        data_dir = os.path.join(data_dir, radar_type)\n",
    "        humans, nonhumans, labels = get_humans_nonhumans(data_dir, humans=None, nonhumans=None)\n",
    "\n",
    "        data = np.vstack((humans, nonhumans)) \n",
    "        labels = np.array(labels)\n",
    "    else:\n",
    "        humans = None\n",
    "        nonhumans=None\n",
    "        radar_types = ['Austere', 'Bumblebee']\n",
    "        for radar_type in radar_types:\n",
    "            radar_data_dir = os.path.join(data_dir, radar_type)\n",
    "            humans, nonhumans, labels = get_humans_nonhumans(radar_data_dir, \n",
    "                                                             humans=humans, \n",
    "                                                             nonhumans=nonhumans)\n",
    "\n",
    "        data = np.vstack((humans, nonhumans)) \n",
    "        labels = np.array(labels)\n",
    "\n",
    "    n_data = data.swapaxes(1, 2)\n",
    "    data = np.absolute(n_data) #(no_of_windows, 5, 256)\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(data, \n",
    "                                                                labels,\n",
    "                                                                test_size=0.1,\n",
    "                                                                random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, \n",
    "                                                      y_train_val,\n",
    "                                                      test_size=0.1,\n",
    "                                                      random_state=42)\n",
    "\n",
    "    if scaling:\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train.reshape(X_train.shape[0], -1))\n",
    "        X_train = scaler.transform(X_train.reshape(X_train.shape[0], -1))\n",
    "        X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "        X_val = scaler.transform(X_val.reshape(X_val.shape[0], -1))\n",
    "\n",
    "        X_train = X_train.reshape(X_train.shape[0], n_data.shape[1], n_data.shape[2])\n",
    "        X_test = X_test.reshape(X_test.shape[0], n_data.shape[1], n_data.shape[2])\n",
    "        X_val = X_val.reshape(X_val.shape[0], n_data.shape[1], n_data.shape[2])\n",
    "        \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Statistics*\n",
    "- Austere: Humans - 15021; Nonhumans - 7170; Total - 22191\n",
    "- Bumblebee: Humans - 8594; Nonhumans - 23594; Total - 32188 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_type = ''\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "dropout = 0.3\n",
    "hidden_1 = 128\n",
    "dense_1 = 64\n",
    "\n",
    "model_dir = '/scratch/sk7898/pedbike/models/upstream'\n",
    "\n",
    "if radar_type:\n",
    "    model_dir = os.path.join(model_dir, radar_type)\n",
    "    model_path = os.path.join(model_dir, 'best_model.h5')\n",
    "else:\n",
    "    model_dir = os.path.join(model_dir, 'Austere_Bumblebee')\n",
    "    model_path = os.path.join(model_dir, 'best_model.h5') #(44046, 5, 256) (4895, 5, 256) (5438, 5, 256)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_upstream_data(radar_type=radar_type)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "model = build_lstm_fft_model(hidden_1,\n",
    "                             dense_1,\n",
    "                             dropout=dropout,\n",
    "                             optimizer=optimizer,\n",
    "                             input_shape=(5, 256))\n",
    "\n",
    "H_train = model.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True)\n",
    "\n",
    "predictions = model.evaluate(x=X_test, y=y_test)\n",
    "print(predictions)\n",
    "\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
