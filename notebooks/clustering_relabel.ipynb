{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sk7898/deep_radar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%cd '/scratch/sk7898/deep_radar'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn import metrics\n",
    "from data import get_fft_data\n",
    "from clustering_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model_path, data_dir, cls, layer_name, pca_train):\n",
    "    \n",
    "    X, X_test, y, y_test, old_y, old_y_test, _, _ = get_fft_data(data_dir, sel_cls=cls, data_mode='amp')    \n",
    "    old_y, y_test, old_y_test = old_y.flatten(), y_test.flatten(), old_y_test.flatten()\n",
    "\n",
    "    model = load_model(model_path)    \n",
    "    model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    #print(model.summary())\n",
    "    emb_train = model.predict(x=X)\n",
    "    emb_test = model.predict(x=X_test)\n",
    "    \n",
    "    X_train, X_test = get_pca_comps(emb_train, emb_test) if pca_train else (emb_train, emb_test)\n",
    "    \n",
    "    return X_train, X_test, old_y, old_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(cls, cluster_id, n_samples,\n",
    "              dist_sum=None, dist_mean=None, dist_max=None, \n",
    "              thresh_clusters=None,\n",
    "              end_cls=False):\n",
    "    \n",
    "    if dist_mean:\n",
    "        print(\n",
    "            f'{cls: ^7}'\n",
    "            f'{cluster_id: ^10}'\n",
    "            f'{n_samples:^10}'\n",
    "            f'{\" \":<4} {dist_mean:.2f}'\n",
    "            f'{\" \":<4} {dist_max:.2f}'\n",
    "            f'{\" \":<8} {thresh_clusters}'\n",
    "            )\n",
    "    elif dist_sum and not end_cls:\n",
    "        print(\n",
    "            f'{cls: ^7}'\n",
    "            f'{cluster_id: ^10}'\n",
    "            f'{n_samples:^10}'\n",
    "            f'{\" \":<4} {dist_sum:.2f}'\n",
    "            )  \n",
    "    elif dist_sum and end_cls:\n",
    "        print('--------------------------------------------------------')\n",
    "        print(\n",
    "            f'{cls: ^7}'\n",
    "            f'{\"#Clusters:\"}{cluster_id: ^4}'\n",
    "            f'{\"#Samples:\"}{n_samples:^8}'\n",
    "            f'{\"Avg Distance:\"} {dist_sum:.2f}'\n",
    "            )   \n",
    "        print('--------------------------------------------------------')\n",
    "    else:\n",
    "        print('Unrecognized options for print!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_h_score_clusters(count_cls, \n",
    "                           h_clusters, h_modes, n_samples, \n",
    "                           cluster_dist_matrix,\n",
    "                           mean_stats=False):\n",
    "    if mean_stats:\n",
    "        print(f'{\"Label\": ^5} | {\"Cluster Id\": ^8} | {\"Samples\": ^8} |'\n",
    "              f'{\"Mean Dist\": ^8} | {\"Max Dist\": ^8} | {\"Clusters with Dist > Mean Dist\"}\\n')\n",
    "    else:\n",
    "        print(f'{\"Label\": ^5} | {\"Cluster Id\": ^8} | {\"Samples\": ^8} | {\"Avg. Dist\": ^10}') \n",
    "       \n",
    "    n_clusters = cluster_dist_matrix.shape[0]\n",
    "    for cls in count_cls:\n",
    "        indices = h_modes == cls\n",
    "        if len(indices) > 0:\n",
    "            cls_clusters = h_clusters[indices]\n",
    "            cls_samples = n_samples[indices]\n",
    "            clust_dists = cluster_dist_matrix[cls_clusters]\n",
    "            dist_sums = np.sum(clust_dists, axis=1)\n",
    "            \n",
    "            if mean_stats:\n",
    "                dist_means = np.mean(clust_dists, axis=1)\n",
    "                dist_maxs = np.max(clust_dists, axis=1)\n",
    "                clust_with_thresh_dist = [len(clust[clust>dist]) for clust, dist in zip(clust_dists, dist_means)]\n",
    "\n",
    "            for i, (clust, smpls) in enumerate(zip(cls_clusters, cls_samples)):\n",
    "                if mean_stats:\n",
    "                    print_row(cls, clust, smpls, \n",
    "                              dist_sum=dist_sums[i],\n",
    "                              dist_mean=dist_means[i]/n_clusters, \n",
    "                              dist_max=dist_maxs[i], \n",
    "                              thresh_clusters=clust_with_thresh_dist[i])\n",
    "                else:\n",
    "                    print_row(cls, clust, smpls, \n",
    "                              dist_sum=dist_sums[i]/n_clusters)\n",
    "\n",
    "            if not mean_stats:\n",
    "                print_row(cls, len(cls_clusters), cls_samples.sum(), \n",
    "                          dist_sum=np.mean(dist_sums)/n_clusters, \n",
    "                          end_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clust_dist_matrix(cluster_cents, cluster_modes, n_clusters):\n",
    "        \n",
    "    if len(cluster_modes.shape) == 1:\n",
    "        cluster_modes = cluster_modes.reshape(cluster_modes.shape[0], 1)\n",
    "        \n",
    "    weights = 1 + np.abs(np.subtract(cluster_modes, cluster_modes.T))\n",
    "    clust_dists = weights * metrics.pairwise.euclidean_distances(cluster_cents)\n",
    "        \n",
    "    return clust_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homogeneity_score(labels, threshold):\n",
    "    label_idx = np.unique(labels, return_inverse=True)[1]\n",
    "    pi = np.bincount(label_idx).astype(np.float)\n",
    "    pi = pi[pi > 0]\n",
    "    pi_sum = np.sum(pi)\n",
    "    probs = pi/pi_sum\n",
    "    scores_above_thresh = probs[probs >= threshold]\n",
    "    print(probs)\n",
    "    \n",
    "    return_val = max(scores_above_thresh) if len(scores_above_thresh) > 0 else 0\n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_kmeans(X, y, n_clusters, n_classes=4):\n",
    "        \n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=n_classes)\n",
    "    kmeans.fit(X)\n",
    "        \n",
    "    cluster_labels = kmeans.predict(X)        \n",
    "    cluster_cents = kmeans.cluster_centers_\n",
    "    cluster_modes = get_cluster_mode(y, cluster_labels, n_clusters=n_clusters)\n",
    "    \n",
    "    return kmeans, cluster_labels, cluster_cents, cluster_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_homogeneous_clusters(y_true, cluster_labels, cluster_modes, n_clusters, homogeneity_threshold=0.8):\n",
    "    homogeneous_clusters = []\n",
    "    homogeneous_labels = [] \n",
    "    homogeneity_scores = []\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        indexes = cluster_labels.flatten() == i\n",
    "        score = get_homogeneity_score(y_true[indexes], homogeneity_threshold)\n",
    "        #score = metrics.cluster.homogeneity_score(y_true[indexes], cluster_labels[indexes])\n",
    "        if score > 0:                        # score > homogeneity_threshold\n",
    "            homogeneous_clusters.append(i)\n",
    "            homogeneous_labels.append(cluster_modes[i])\n",
    "            homogeneity_scores.append(score)\n",
    "\n",
    "    return np.array(homogeneity_scores), np.array(homogeneous_clusters), np.array(homogeneous_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_check(to_add, to_remove, dists, threshold):\n",
    "    all_but_one = np.concatenate([dists[:to_remove], dists[to_remove+1:]])\n",
    "    if np.min(all_but_one) > threshold:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_dist_clusters(X,\n",
    "                        h_clusters, \n",
    "                        cluster_labels,\n",
    "                        cluster_modes, \n",
    "                        n_clusters,\n",
    "                        dist_threshold=0):\n",
    "    \n",
    "    ideal_clusters, X_min_dists = [], []\n",
    "    dist_dict = {}\n",
    "    \n",
    "    # For all cluster i in Homogeneous clusters H, get the pairwise distance of all samples of cluster i \n",
    "    # with all the other clusters in Homogeneous clusters which do not belong to the same class (calculated by the mode)\n",
    "    for clust_id in h_clusters:\n",
    "        indexes, smpls_end_idx = [], [0]\n",
    "        end_idx_dict = {}\n",
    "        idx = [i for i in h_clusters if cluster_modes[i] != cluster_modes[clust_id]]\n",
    "        for c_id in idx:\n",
    "            idxs, _ = np.where(cluster_labels.reshape(-1, 1) == c_id)\n",
    "            end_idx = smpls_end_idx[-1] + len(idxs) - 1\n",
    "            smpls_end_idx.append(end_idx)\n",
    "            end_idx_dict[end_idx] = c_id\n",
    "            indexes += list(idxs)\n",
    "           \n",
    "        X_ref = X[cluster_labels.flatten() == clust_id]\n",
    "        X_clusters = X[indexes]\n",
    "        dists = metrics.pairwise.euclidean_distances(X_ref, X_clusters)\n",
    "        # Get the minimum value from the pairwise distances matrix\n",
    "        min_dist = np.min(dists)\n",
    "        \n",
    "        # Add the cluster to the list of ideal_clusters if the minimum distance is above the dist_threshold\n",
    "        # Save all the cluster pairs which has violate the dist_threshold requirement\n",
    "        if min_dist > dist_threshold:\n",
    "            X_min_dists.append(min_dist)\n",
    "            ideal_clusters.append(clust_id)\n",
    "        else:\n",
    "            smpls_end_idx = np.array(smpls_end_idx)\n",
    "            idx_x, idx_y = np.where(dists <= dist_threshold)\n",
    "            for x, y in zip(idx_x, idx_y):\n",
    "                temp_idxs = smpls_end_idx >= y\n",
    "                if len(smpls_end_idx[temp_idxs]) > 0:\n",
    "                    end_idx = smpls_end_idx[temp_idxs][0]\n",
    "                    dist_dict[(clust_id, end_idx_dict[end_idx])] = dists[x, y]\n",
    "        \n",
    "    # For (c1, c2) cluster pair, if c2 is the only one causing violation in c1 and the other way around\n",
    "    # Include c1 or c2 depending on the class representations we already have in the ideal_clusters\n",
    "    modes_till_now, mode_counts = np.unique(cluster_modes[ideal_clusters], return_counts=True)\n",
    "    for key, val in dist_dict.items():\n",
    "        c1, c2 = key[0], key[1]\n",
    "        c1_cls, c2_cls = cluster_modes[c1], cluster_modes[c2]\n",
    "        if (c2, c1) in dist_dict.keys() and c1 not in ideal_clusters and c2 not in ideal_clusters:\n",
    "            count_c1 = mode_counts[modes_till_now == c1_cls] if c1_cls in modes_till_now else 0\n",
    "            count_c2 = mode_counts[modes_till_now == c2_cls] if c2_cls in modes_till_now else 0\n",
    "            if count_c1 < count_c2 and dist_check(c1, c2, dists[c1], dist_threshold):\n",
    "                ideal_clusters.append(c1)\n",
    "                X_min_dists.append(val)\n",
    "            elif dist_check(c2, c1, dists[c2], dist_threshold):\n",
    "                ideal_clusters.append(c2)\n",
    "                X_min_dists.append(val)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return ideal_clusters, X_min_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideal_clusters(X, y_true, \n",
    "                       cluster_labels, \n",
    "                       n_clusters, \n",
    "                       cluster_cents, \n",
    "                       cluster_modes,\n",
    "                       count_cls=[1, 2, 3, 4],\n",
    "                       homogeneity_threshold=0.8,\n",
    "                       dist_threshold=0,\n",
    "                       mean_stats=False,\n",
    "                       verbose=0):\n",
    "    \n",
    "    cluster_dist_matrix = get_clust_dist_matrix(cluster_cents,\n",
    "                                                cluster_modes, \n",
    "                                                n_clusters)\n",
    "    h_scores, h_clusters, h_modes = ideal_homogeneous_clusters(y_true, \n",
    "                                                               cluster_labels,\n",
    "                                                               cluster_modes,\n",
    "                                                               n_clusters,\n",
    "                                                               homogeneity_threshold=homogeneity_threshold)\n",
    "    n_samples = get_n_samples(h_clusters, cluster_labels)        \n",
    "     \n",
    "    if verbose:\n",
    "        print_h_score_clusters(count_cls, h_clusters, h_modes, n_samples, cluster_dist_matrix, \n",
    "                               mean_stats=mean_stats)\n",
    "    \n",
    "    if dist_threshold:\n",
    "        ideal_clusters, cluster_min_dists = ideal_dist_clusters(X,\n",
    "                                                                h_clusters,\n",
    "                                                                cluster_labels,\n",
    "                                                                cluster_modes, \n",
    "                                                                n_clusters, \n",
    "                                                                dist_threshold=dist_threshold)\n",
    "        \n",
    "        return ideal_clusters, h_clusters, h_scores, h_modes, cluster_min_dists\n",
    "    \n",
    "    else:\n",
    "        return h_clusters, h_clusters, h_scores, h_modes, cluster_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_points(X_subset, y_subset, \n",
    "                   non_h_indexes,\n",
    "                   ideal_clusters, \n",
    "                   cluster_cents, \n",
    "                   cluster_modes,\n",
    "                   dist_diff_thresh=None):\n",
    "    \n",
    "    new_y = y_subset.copy()\n",
    "    was_changed = np.zeros(len(y_subset), dtype='int')\n",
    "    \n",
    "    h_cents = cluster_cents[ideal_clusters]\n",
    "    ideal_clust_modes = cluster_modes[ideal_clusters]\n",
    "    dists = metrics.pairwise.euclidean_distances(X_subset, h_cents)\n",
    "    min_dist = np.min(dists, axis=1)\n",
    "    min_dist_idx = np.argmin(dists, axis=1)\n",
    "    \n",
    "    \n",
    "    for idx, x in enumerate(X_subset):\n",
    "        closest_cluster = ideal_clusters[min_dist_idx[idx]]\n",
    "        closest_cluster_cls = cluster_modes[closest_cluster]\n",
    "        x_clust_dists = dists[idx][ideal_clust_modes != closest_cluster_cls]\n",
    "        min_diff_dist = np.min(x_clust_dists)/min_dist[idx]\n",
    "        #min_diff_dist = np.min(x_clust_dists - min_dist[idx])\n",
    "        if min_diff_dist > dist_diff_thresh:\n",
    "            new_y[idx] = closest_cluster_cls\n",
    "            was_changed[idx] = 1\n",
    "            \n",
    "    return new_y, was_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_samples(X_train, y_train,\n",
    "                        ideal_clusters,\n",
    "                        h_clusters,\n",
    "                        cluster_labels):\n",
    "    \n",
    "    indexes, non_h_indexes, h_indexes = [], [], []\n",
    "    cluster_labels = cluster_labels.reshape(-1, 1)\n",
    "    \n",
    "    for clust_id in ideal_clusters:\n",
    "        idxs, _ = np.where(cluster_labels == clust_id)\n",
    "        indexes += list(idxs)\n",
    "\n",
    "    for clust_id in h_clusters:\n",
    "        idxs, _ = np.where(cluster_labels == clust_id)\n",
    "        h_indexes += list(idxs)\n",
    "        \n",
    "    X_subset = X_train[indexes]\n",
    "    c_labels = cluster_labels[indexes]\n",
    "    c_labels = c_labels.flatten()\n",
    "    \n",
    "    non_h_indexes = [i for i in range(X_train.shape[0]) if i not in indexes]\n",
    "    X_non_h_subset = X_train[non_h_indexes]\n",
    "    y_non_h_subset = y_train[non_h_indexes]\n",
    "    \n",
    "    return X_subset, c_labels, X_non_h_subset, y_non_h_subset, indexes, non_h_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(axs, X, y,\n",
    "          row_plt, \n",
    "          col_idx,\n",
    "          row_idx=None,\n",
    "          palette=None,\n",
    "          param_str=None,\n",
    "          X_changed=None,\n",
    "          ideal_clusters=None,\n",
    "          plot_cents=None,\n",
    "          annotation=None):\n",
    "\n",
    "    c_palette = palette if palette is not None else sns.color_palette(\"bright\", len(np.unique(y)))\n",
    "    ax = axs[row_idx, col_idx] if row_idx is not None else axs[col_idx]\n",
    "    ax.set_xlim([-20, 20])\n",
    "        \n",
    "    if (row_idx == 0 or row_idx is None) and param_str:\n",
    "        ax.set_title(param_str)\n",
    "        \n",
    "    if row_plt == 'pca':\n",
    "        sns.scatterplot(X[:, 0], X[:, 1], \n",
    "                        hue=y,\n",
    "                        legend='full', \n",
    "                        palette=c_palette,\n",
    "                        ax=ax)\n",
    "        \n",
    "    if row_plt == 'samples':\n",
    "        if plot_cents is None or annotation is None:\n",
    "            raise ValueError('Missing list of number of samples to plot')\n",
    "            \n",
    "        p2 = sns.scatterplot(X[:, 0], X[:, 1], \n",
    "                             hue=y,\n",
    "                             legend=False, \n",
    "                             palette=c_palette,\n",
    "                             ax=ax)\n",
    "        \n",
    "        for i, c in enumerate(plot_cents):\n",
    "            p2.text(c[0], c[1],\n",
    "                    annotation[i],\n",
    "                    horizontalalignment='left',\n",
    "                    size='large',\n",
    "                    color='black',\n",
    "                    weight='semibold')\n",
    "        \n",
    "    if row_plt == 'dist_thresh':\n",
    "        if plot_cents is None or annotation is None:\n",
    "            raise ValueError('Missing list of number of samples to plot')\n",
    "        \n",
    "        p1 = sns.scatterplot(X[:, 0], X[:, 1], \n",
    "                             hue=y,\n",
    "                             legend=False, \n",
    "                             palette=c_palette,\n",
    "                             ax=ax)\n",
    "\n",
    "        for i, c in enumerate(plot_cents):\n",
    "            p1.text(c[0], c[1],\n",
    "                    round(annotation[i], 1),\n",
    "                    horizontalalignment='left',\n",
    "                    bbox=dict(facecolor='red', alpha=0.5),\n",
    "                    size='large',\n",
    "                    color='white',\n",
    "                    weight='bold')\n",
    "    \n",
    "    if row_plt == 'relabel':\n",
    "        if plot_cents is None or annotation is None or ideal_clusters is None:\n",
    "            raise ValueError('Missing list of number of samples to plot')\n",
    "            \n",
    "        p1 = sns.scatterplot(X[:, 0], X[:, 1], \n",
    "                             legend=False, \n",
    "                             color='black',\n",
    "                             ax=ax)\n",
    "    \n",
    "        p2 = sns.scatterplot(X_changed[:, 0], X_changed[:, 1], \n",
    "                             hue=y,\n",
    "                             legend=False, \n",
    "                             palette=c_palette,\n",
    "                             ax=ax)\n",
    "        \n",
    "        for i, c in enumerate(plot_cents):\n",
    "            p1.text(c[0], c[1],\n",
    "                    annotation[ideal_clusters[i]],\n",
    "                    horizontalalignment='left',\n",
    "                    bbox=dict(facecolor='red', alpha=0.5),\n",
    "                    size='large',\n",
    "                    color='white',\n",
    "                    weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = True\n",
    "sel_cls = [1, 2, 3, 4]\n",
    "n_classes = len(sel_cls)\n",
    "radar_dir = '/scratch/sk7898/radar_data/pedbike'\n",
    "data_dir = os.path.join(radar_dir, 'regression_fft_data')\n",
    "\n",
    "if regression:\n",
    "    cls_str = '1_2_3_4'\n",
    "    model_dir = os.path.join(radar_dir, 'models/lstm') \n",
    "    layer_name = 'counting_dense_2'\n",
    "    model_str = os.path.join(cls_str + '_amp_512_hidden_128/model_best_valid_loss_dp_4.h5')\n",
    "    model_path = os.path.join(model_dir, model_str)\n",
    "else:\n",
    "    radar_type = 'Bumblebee'\n",
    "    model_dir =  os.path.join(radar_dir, 'models/upstream', radar_type)\n",
    "    layer_name = 'dense_1'\n",
    "    model_path = os.path.join(model_dir, 'best_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16017, 64) (1780, 64)\n",
      "[0.64895636 0.25616698 0.06641366 0.028463  ]\n",
      "[0.00735294 0.99264706]\n",
      "[0.00564972 0.94350282 0.05084746]\n",
      "[0.95752896 0.02702703 0.01544402]\n",
      "[1.]\n",
      "[0.00406504 0.98780488 0.00813008]\n",
      "[0.10638298 0.89361702]\n",
      "[0.02766798 0.21343874 0.72727273 0.03162055]\n",
      "[0.00483092 0.0531401  0.94202899]\n",
      "[0.99009901 0.00990099]\n",
      "[0.00584795 0.91520468 0.07894737]\n",
      "[0.0026738  0.94385027 0.02941176 0.02406417]\n",
      "[0.04487179 0.89102564 0.06410256]\n",
      "[0.92995169 0.0410628  0.02898551]\n",
      "[0.18479685 0.31323722 0.20314548 0.29882045]\n",
      "[0.98901099 0.01098901]\n",
      "[0.02564103 0.97435897]\n",
      "[0.02339181 0.96491228 0.01169591]\n",
      "[0.98958333 0.01041667]\n",
      "[0.18402778 0.81597222]\n",
      "[0.97452229 0.02547771]\n",
      "[0.01408451 0.94014085 0.04577465]\n",
      "[1.]\n",
      "[0.00990099 0.00990099 0.01485149 0.96534653]\n",
      "[0.01857143 0.03571429 0.84       0.10571429]\n",
      "[0.51476793 0.17299578 0.31223629]\n",
      "[1.]\n",
      "[0.03603604 0.94594595 0.01801802]\n",
      "[0.03351955 0.96089385 0.00558659]\n",
      "[0.01639344 0.0273224  0.95628415]\n",
      "[0.04552846 0.63414634 0.24390244 0.07642276]\n",
      "[0.03738318 0.96261682]\n",
      "[0.01126126 0.04504505 0.31531532 0.62837838]\n",
      "[0.00862069 0.04741379 0.52155172 0.42241379]\n",
      "[0.01456311 0.2038835  0.7815534 ]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.97435897 0.00512821 0.02051282]\n",
      "[0.00421941 0.98312236 0.01265823]\n",
      "[0.97222222 0.01851852 0.00462963 0.00462963]\n",
      "[0.02189781 0.97810219]\n",
      "[0.990625 0.00625  0.003125]\n",
      "[0.99507389 0.00492611]\n",
      "[0.20491803 0.72131148 0.04098361 0.03278689]\n",
      "[1.]\n",
      "[0.00458716 0.99082569 0.00458716]\n",
      "[0.00671141 0.01006711 0.02348993 0.95973154]\n",
      "[0.01142857 0.02285714 0.04571429 0.92      ]\n",
      "[0.97709924 0.00763359 0.01526718]\n",
      "[0.89285714 0.08418367 0.01785714 0.00510204]\n",
      "[0.0255102 0.9744898]\n",
      "[1.]\n",
      "[0.90384615 0.09615385]\n",
      "[0.015 0.975 0.01 ]\n",
      "[0.99052133 0.00947867]\n",
      "[0.01782178 0.01782178 0.27326733 0.69108911]\n",
      "[0.00378788 0.98106061 0.01515152]\n",
      "[0.0125 0.9625 0.0125 0.0125]\n",
      "[0.98765432 0.01234568]\n",
      "[0.9862069 0.0137931]\n",
      "[ 1  4  5  9 15 18 22 26 35 36 38 41 42 44 45 51 54 56 58 59] [ 1  4  5  9 15 18 22 26 35 36 38 41 42 44 45 51 54 56 58 59] [0.99264706 1.         0.98780488 0.99009901 0.98901099 0.98958333\n",
      " 1.         1.         1.         1.         0.98312236 0.990625\n",
      " 0.99507389 1.         0.99082569 1.         0.99052133 0.98106061\n",
      " 0.98765432 0.9862069 ]\n"
     ]
    }
   ],
   "source": [
    "n_clusters, homogeneity_threshold, dist_threshold, diff_thresh = 60, 0.98, 0, 1.5\n",
    "cluster_list = [60]\n",
    "#h_thresh_list = [0.98, 0.99, 1]\n",
    "#dist_thresh_list = [0.5, 1.5, 2.5, 3.5]\n",
    "plot_row_list = ['samples'] #'dist_thresh', 'relabel']\n",
    "\n",
    "pca_train = False\n",
    "plot_pca = False\n",
    "plot_ideal = True\n",
    "plot_rows = len(plot_row_list)\n",
    "plot_cols = len(cluster_list)\n",
    "plot_height = 7 * plot_rows\n",
    "plot_width = 9 * plot_cols\n",
    "\n",
    "X_train, X_test, old_y, old_y_test = get_embeddings(model_path, \n",
    "                                                    data_dir,\n",
    "                                                    cls=sel_cls, \n",
    "                                                    layer_name=layer_name, \n",
    "                                                    pca_train=pca_train)\n",
    "print(X_train.shape, X_test.shape)\n",
    "    \n",
    "if pca_train:\n",
    "    sns.set(rc={'figure.figsize':(plot_width, plot_height)})    \n",
    "    fig, axs = plt.subplots(nrows=plot_rows, ncols=plot_cols, sharey=True)\n",
    "\n",
    "    if plot_pca:\n",
    "        row_idx = None if len(plot_row_list) == 1 else 0\n",
    "        plots(axs, X_train, old_y, \n",
    "              row_plt='pca', \n",
    "              param_str='X_train (PCA)',\n",
    "              row_idx=row_idx, col_idx=0)\n",
    "        \n",
    "for idx, n_clusters in enumerate(cluster_list): \n",
    "    kmeans, cluster_labels, cluster_cents, cluster_modes = X_kmeans(X_train, old_y,\n",
    "                                                                    n_clusters=n_clusters,\n",
    "                                                                    n_classes=n_classes)\n",
    "    \n",
    "    ideal_clusters, h_clusters, scores, modes, dists = get_ideal_clusters(X_train, \n",
    "                                                                          old_y, \n",
    "                                                                          cluster_labels,\n",
    "                                                                          n_clusters,\n",
    "                                                                          cluster_cents,\n",
    "                                                                          cluster_modes,\n",
    "                                                                          count_cls=sel_cls,\n",
    "                                                                          homogeneity_threshold=homogeneity_threshold,\n",
    "                                                                          dist_threshold=dist_threshold)\n",
    "    \n",
    "    print(ideal_clusters, h_clusters, scores)\n",
    "    \n",
    "    X_subset, c_labels, X_non_h_subset, y_non_h_subset, h_indexes, non_h_indexes = get_cluster_samples(X_train, old_y,\n",
    "                                                                                                       ideal_clusters,\n",
    "                                                                                                       h_clusters,\n",
    "                                                                                                       cluster_labels)\n",
    "    new_y, was_changed = relabel_points(X_non_h_subset, y_non_h_subset, \n",
    "                                        non_h_indexes, \n",
    "                                        ideal_clusters, \n",
    "                                        cluster_cents, \n",
    "                                        cluster_modes, \n",
    "                                        dist_diff_thresh=diff_thresh)\n",
    "    \n",
    "    X_changed = X_non_h_subset[was_changed == 1]\n",
    "    y_changed = y_non_h_subset[was_changed == 1]\n",
    "    \n",
    "    param_str = f'n_clusters:{n_clusters} {\"|\"} h_thresh:{homogeneity_threshold}'\n",
    "    if dist_threshold:\n",
    "        param_str += f' {\"|\"} d_thresh:{dist_threshold}'\n",
    "    if diff_thresh:\n",
    "        param_str += f' {\"|\"} diff_thresh:{diff_thresh}'\n",
    "   \n",
    "    if pca_train:\n",
    "        for i, row_plt in enumerate(plot_row_list):\n",
    "            row_idx = None if len(plot_row_list) == 1 else i\n",
    "            col_idx = idx+1 if plot_pca else idx\n",
    "            plot_cents = [cluster_cents[clust_id] for clust_id in ideal_clusters]\n",
    "\n",
    "            if row_plt == 'samples':\n",
    "                clusters, X, y = (ideal_clusters, X_subset, c_labels) if plot_ideal else (h_clusters, X_train[h_indexes], cluster_labels[h_indexes])\n",
    "                n_samples = get_n_samples(clusters, cluster_labels.flatten())\n",
    "                plots(axs, X, y.flatten(),\n",
    "                      row_plt,\n",
    "                      param_str=param_str,\n",
    "                      plot_cents=plot_cents,\n",
    "                      annotation=n_samples,\n",
    "                      row_idx=row_idx, col_idx=col_idx)\n",
    "\n",
    "            if row_plt == 'dist_thresh':\n",
    "                plots(axs, X_subset, c_labels,\n",
    "                      row_plt,\n",
    "                      param_str=param_str,\n",
    "                      plot_cents=plot_cents,\n",
    "                      annotation=dists,\n",
    "                      row_idx=row_idx, col_idx=col_idx)\n",
    "\n",
    "            if row_plt == 'relabel': \n",
    "                print(f'Relabeled Samples: {len(y_changed != y_non_h_subset[was_changed == 1])}')\n",
    "                plots(axs, X_subset, y_changed,\n",
    "                      row_plt,\n",
    "                      param_str=param_str,\n",
    "                      X_changed=X_changed,\n",
    "                      plot_cents=plot_cents,\n",
    "                      annotation=cluster_modes,\n",
    "                      ideal_clusters=ideal_clusters,\n",
    "                      row_idx=row_idx, col_idx=col_idx)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('l3embedding-tf-2-cpu': conda)",
   "language": "python",
   "name": "python36764bitl3embeddingtf2cpucondaf8a2c7b8f7ff4137a6afe19afb6a1070"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
