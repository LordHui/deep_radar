{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sk7898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2946be1c705c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_fft_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclustering_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn import metrics\n",
    "from data import get_fft_data\n",
    "from clustering_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_dbscan(X_train, y_train,\n",
    "                      min_samples_lst=None,\n",
    "                      eps_lst=None,\n",
    "                      pca_train=True):\n",
    "\n",
    "    if eps_lst and min_samples_lst:\n",
    "        col_names = ['min_samples:'+ str(min_samples)+' eps:' + str(eps) for min_samples in min_samples_lst\n",
    "                                                                         for eps in eps_list \n",
    "                    ]\n",
    "        \n",
    "        fig, axs = get_plot_fig(rows=len(min_samples_lst),\n",
    "                                cols=len(eps_lst),\n",
    "                                col_names=col_names)\n",
    "        \n",
    "        for row_idx, min_samples in enumerate(min_samples_lst):\n",
    "            for col_idx, eps in enumerate(eps_lst):\n",
    "                db = DBSCAN(eps=eps, min_samples=min_samples).fit(X_train)\n",
    "                core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "                core_samples_mask[db.core_sample_indices_] = True\n",
    "                labels = db.labels_\n",
    "                \n",
    "                n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "                n_noise_ = list(labels).count(-1)\n",
    "\n",
    "                print('Estimated number of clusters: %d' % n_clusters_)\n",
    "                print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "                labels_palette = sns.color_palette(\"bright\", len(np.unique(labels)))\n",
    "        \n",
    "                plot_data(axs, X, labels,\n",
    "                          palette=labels_palette,\n",
    "                          row_idx=row_idx,\n",
    "                          col_idx=col_idx,\n",
    "                          legend='full')\n",
    "            \n",
    "                print_scores(y_train, labels)\n",
    "                \n",
    "    else:\n",
    "        db = DBSCAN(eps=0.3, min_samples=10).fit(X_train)\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # DBSCAN helps us to identify noise in the data.\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "        print('Estimated number of clusters: %d' % n_clusters_)\n",
    "        print('Estimated number of noise points: %d' % n_noise_)\n",
    "        \n",
    "        print_scores(y_train, labels)\n",
    "        labels_palette = sns.color_palette(\"bright\", len(np.unique(labels)))\n",
    "        \n",
    "        sns.scatterplot(X[:, 0], X[:, 1], hue=labels, palette=labels_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_agglomerative(X_train, y_train, \n",
    "                             affinity,\n",
    "                             linkage,\n",
    "                             n_clusters,\n",
    "                             pca_train=True):\n",
    "    \n",
    "    # Create a graph capturing local connectivity. Larger number of neighbors\n",
    "    # will give more homogeneous clusters to the cost of computation\n",
    "    # time. A very large number of neighbors gives more evenly distributed\n",
    "    # cluster sizes, but may not impose the local manifold structure of\n",
    "    # the data\n",
    "    \n",
    "    pca = PCA(n_components=2).fit(X_train)\n",
    "    X = pca.transform(X_train)\n",
    "    \n",
    "    X_train = X if pca_train else X_train\n",
    "    \n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(X_train, n_neighbors=10, include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    agg = AgglomerativeClustering(linkage=linkage,\n",
    "                                  affinity=affinity,\n",
    "                                  connectivity=connectivity,\n",
    "                                  n_clusters=n_clusters)\n",
    "    agg.fit(X_train)\n",
    "     \n",
    "    # Print the clustering scores\n",
    "    print_scores(y_train, agg.labels_)\n",
    "    \n",
    "    labels_palette = sns.color_palette(\"bright\", len(np.unique(agg.labels_)))\n",
    "    sns.scatterplot(X[:, 0], X[:, 1], hue=agg.labels_, palette=labels_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_kmeans(X_train, y, old_y, \n",
    "                      X_test, y_test, old_y_test,\n",
    "                      cluster_list,\n",
    "                      col_names,\n",
    "                      sel_cls,\n",
    "                      c_idx, inc_idx,\n",
    "                      pca_train=True):\n",
    "    \n",
    "    def _kmeans_train(X, y, old_y,\n",
    "                     n_clusters, \n",
    "                     n_classes,\n",
    "                     cluster_palette,\n",
    "                     row_idx, col_idx,\n",
    "                     plot=True):\n",
    "\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=n_classes)\n",
    "        kmeans.fit(X)\n",
    "        \n",
    "        clust_labels = kmeans.predict(X)        \n",
    "        cent = kmeans.cluster_centers_\n",
    "        clust_true_labels = get_cluster_mode(old_y, clust_labels, n_clusters=n_clusters)\n",
    "\n",
    "        # print the clustering scores \n",
    "        print_scores(y, clust_labels, n_clusters=n_clusters)\n",
    "        \n",
    "        if plot:\n",
    "            plot_data(axs, X=X, y=clust_labels,\n",
    "                      palette=cluster_palette,\n",
    "                      y_annotate=clust_true_labels,\n",
    "                      cents=cent,\n",
    "                      legend=False,\n",
    "                      row_idx=row_idx, col_idx=col_idx)\n",
    "        \n",
    "            return kmeans, col_idx+1\n",
    "        \n",
    "        else:\n",
    "            return kmeans, col_idx\n",
    "            \n",
    "    def _kmeans_predict(kmeans, X, old_y,\n",
    "                       n_clusters,\n",
    "                       cluster_palette,\n",
    "                       row_idx, col_idx,\n",
    "                       plot=True):\n",
    "        \n",
    "        clust_labels = kmeans.predict(X)\n",
    "        cent_X = kmeans.cluster_centers_\n",
    "        clust_true_labels = get_cluster_mode(old_y, clust_labels, n_clusters=n_clusters)\n",
    "\n",
    "        if plot:\n",
    "            plot_data(axs, X=X, y=clust_labels,\n",
    "                      palette=cluster_palette,\n",
    "                      y_annotate=clust_true_labels,\n",
    "                      cents=cent_X,\n",
    "                      legend=False,\n",
    "                      row_idx=row_idx, col_idx=col_idx)\n",
    "        \n",
    "            return clust_labels, col_idx+1\n",
    "        \n",
    "        else:\n",
    "            return clust_labels, col_idx\n",
    "        \n",
    "    n_classes = len(sel_cls) \n",
    "    plot = True if pca_train else False\n",
    "    pca_plots = list(filter(lambda x: 'PCA' in x, col_names)) \n",
    "    train_kmeans = list(filter(lambda x: 'kmeans trained' in x, col_names)) \n",
    "    test_kmeans = list(filter(lambda x: 'kmeans predict' in x, col_names))\n",
    "        \n",
    "    if plot:\n",
    "        fig, axs = get_plot_fig(rows=len(cluster_list),\n",
    "                                cols=len(col_names),\n",
    "                                col_names=col_names)\n",
    "        true_palette = sns.color_palette(\"bright\", n_classes)\n",
    "\n",
    "    \n",
    "    X_c, y_c, old_y_c = get_subset_data(X=X_train,\n",
    "                                        y=y,\n",
    "                                        old_y=old_y,\n",
    "                                        idxs=c_idx)\n",
    "\n",
    "    X_inc, y_inc, old_y_inc = get_subset_data(X=X_train,\n",
    "                                              y=y,\n",
    "                                              old_y=old_y,\n",
    "                                              idxs=inc_idx)\n",
    "    data_dict = { \n",
    "                    'train': (X_train, y, old_y),\n",
    "                    'test': (X_test, y_test, old_y_test),\n",
    "                    'c': (X_c, y_c, old_y_c),\n",
    "                    'inc': (X_inc, y_inc, old_y_inc)\n",
    "                }\n",
    "    \n",
    "    for i, n_clusters in enumerate(cluster_list):\n",
    "        col_idx = 0\n",
    "        cluster_palette = sns.color_palette(\"bright\", n_clusters)\n",
    "\n",
    "        print('***********************n_clusters={}*******************************'.format(n_clusters))\n",
    "        \n",
    "        if plot and len(pca_plots) > 0:\n",
    "            for col in pca_plots:\n",
    "                key = col.split('_')[1]\n",
    "                try:\n",
    "                    X,_, y = data_dict[key]\n",
    "                except:\n",
    "                    print('Unrecognized Dataset!')\n",
    "                \n",
    "                cents = cluster_centroids(X, y, n_classes=n_classes)\n",
    "                plot_data(axs, X=X, y=y,\n",
    "                          palette=true_palette,\n",
    "                          y_annotate=sel_cls,\n",
    "                          cents=cents,\n",
    "                          row_idx=i, col_idx=col_idx)\n",
    "                col_idx += 1\n",
    "          \n",
    "        if len(train_kmeans) > 0:\n",
    "            for col in train_kmeans:\n",
    "                key = col.split('_')[1]\n",
    "                try:\n",
    "                    X, y, old_y = data_dict[key]\n",
    "                except:\n",
    "                    print('Unrecognized Dataset!')\n",
    "                    \n",
    "                print('Clustering Scores on X_{} when trained with X_{}'.format(key))\n",
    "                kmeans, col_idx = _kmeans_train(X, y, old_y,\n",
    "                                               n_clusters=n_clusters,\n",
    "                                               n_classes=n_classes,\n",
    "                                               cluster_palette=cluster_palette,\n",
    "                                               row_idx=i, col_idx=col_idx,\n",
    "                                               plot=plot)\n",
    "\n",
    "        if len(test_kmeans) > 0:\n",
    "            for col in test_kmeans:\n",
    "                key = col.split('_')[1]\n",
    "                try:\n",
    "                    X, _, y = data_dict[key]\n",
    "                except:\n",
    "                    print('Unrecognized Dataset!')\n",
    "                    \n",
    "            # Plot cluster predictions on X_inc\n",
    "            clust_labels, col_idx = _kmeans_predict(kmeans, X, y,\n",
    "                                                   n_clusters=n_clusters,\n",
    "                                                   cluster_palette=cluster_palette,\n",
    "                                                   row_idx=i, col_idx=col_idx,\n",
    "                                                   plot=plot)\n",
    "            if key == 'test':\n",
    "                print('Clustering Scores on X_test')\n",
    "                print_scores(y_test, clust_labels, n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'kmeans'\n",
    "model_dir = '/scratch/sk7898/pedbike/models/lstm/'\n",
    "cls_str_list = ['1_2_3_4']\n",
    "sel_cls_list = [[1, 2, 3, 4]]\n",
    "layer_name = 'counting_dense_2'\n",
    "pca_train = True\n",
    "relabel = True\n",
    "    \n",
    "for idx, (cls_str, sel_cls) in enumerate(zip(cls_str_list, sel_cls_list)):\n",
    "    model_str = os.path.join(cls_str + '_amp_512_hidden_128/best_model.h5')\n",
    "    model_path = os.path.join(model_dir, model_str)\n",
    "\n",
    "    X, X_test, y, y_test, old_y, old_y_test, _, _ = get_fft_data(sel_cls=sel_cls, data_mode='amp')\n",
    "    \n",
    "    old_y, y_test, old_y_test = old_y.flatten(), y_test.flatten(), old_y_test.flatten()\n",
    "\n",
    "    c_idx, inc_idx = get_correct_incorrect_idx(model_path,\n",
    "                                               X,\n",
    "                                               y_true=y, \n",
    "                                               n_classes=len(sel_cls)) \n",
    "    \n",
    "    model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    emb_train = model.predict(x=X)\n",
    "    emb_test = model.predict(x=X_test)\n",
    "    \n",
    "    X_train, X_test = get_pca_comps(emb_train, emb_test) if pca_train else (emb_train, emb_test)\n",
    "    \n",
    "    if method == 'kmeans':\n",
    "        cluster_list = [20]\n",
    "        # Options: PCA X_train, PCA X_test, PCA X_inc\n",
    "        #          kmeans trained with X_train, kmeans trained with X_c\n",
    "        #          kmeans predict X_test, kmeans predict X_inc\n",
    "        col_names = [\n",
    "                     'kmeans trained with X_c',\n",
    "                     #'kmeans predict X_test'\n",
    "                    ]\n",
    "          \n",
    "        clustering_kmeans(X_train, y, old_y,\n",
    "                          X_test, y_test, old_y_test,\n",
    "                          cluster_list=cluster_list,\n",
    "                          col_names=col_names,\n",
    "                          sel_cls=sel_cls,\n",
    "                          c_idx=c_idx, inc_idx=inc_idx\n",
    "                         )\n",
    "        \n",
    "    if method == 'DBSCAN':\n",
    "        min_samples_lst = [2, 5, 10]\n",
    "        eps_lst = [0.3, 0.5, 1.0, 1.5]\n",
    "        clustering_dbscan(X_train, y,\n",
    "                          min_samples_lst=min_samples_lst,\n",
    "                          eps_lst=eps_lst\n",
    "                         )\n",
    "        \n",
    "    if method == 'Agglomerative':\n",
    "        clustering_agglomerative(X_train, y,\n",
    "                                 affinity='euclidean',\n",
    "                                 linkage='ward',  \n",
    "                                 n_clusters=8\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
