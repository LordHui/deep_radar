{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import PurePath\n",
    "from shutil import copy, rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data2IQ(filepath):\n",
    "    # Ref: https://github.com/dhruboroy29/MATLAB_Scripts/blob/6ded2d8d434239e3488ee79e02232dd7afff908c/Scripts/Data2IQ.m\n",
    "    # Read IQ streams from data\n",
    "    assert os.path.splitext(filepath)[1] == '.data' or os.path.splitext(filepath)[1] == '.bbs'\n",
    "    comp = np.fromfile(filepath, dtype=np.uint16)\n",
    "    I = comp[::2]\n",
    "    Q = comp[1::2]\n",
    "    try:\n",
    "        assert len(I) == len(Q)\n",
    "    except AssertionError as e:\n",
    "        e.args += (filepath,42)\n",
    "        raise\n",
    "\n",
    "    # Sanity check of I and Q samples (>4096, or abruptly different from prev. sample?)\n",
    "    for i in range(1,len(I)-1):\n",
    "        if I[i]>4096 or abs(int(I[i])-int(I[i-1]))>2000 and abs(int(I[i])-int(I[i+1]))>1500:\n",
    "            I[i] = I[i-1]\n",
    "        if Q[i]>4096 or abs(int(Q[i])-int(Q[i-1]))>2000 and abs(int(Q[i])-int(Q[i+1]))>1500:\n",
    "            Q[i] = Q[i-1]\n",
    "\n",
    "    return I,Q,len(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series_data(fileloc, data_dir, label, win_len, fraction=None):\n",
    "    filenames = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    seqs = []\n",
    "    \n",
    "    [[filenames.append(os.path.join(os.path.join(fileloc, filestr), filename))\\\n",
    "      for filename in os.listdir(os.path.join(fileloc, filestr))] for filestr in data_dir]\n",
    "    \n",
    "    for file in filenames:\n",
    "        I,Q,L = Data2IQ(file)\n",
    "        \n",
    "        windows = list(range(0, L - win_len + 1, win_len))\n",
    "        labels.append(label)\n",
    "        seqs.append(len(windows))\n",
    "        data_cut = np.zeros((len(windows), 2 * win_len), dtype=np.uint16)\n",
    "        \n",
    "        for k in range(len(windows)):\n",
    "            data_cut[k, ::2] = I[windows[k]: windows[k] + win_len]\n",
    "            data_cut[k, 1::2] = Q[windows[k]: windows[k] + win_len]\n",
    "        \n",
    "        data.append(data_cut)\n",
    "\n",
    "    if fraction:\n",
    "        indices = np.arange(len(filenames))\n",
    "        subset_indices = random.sample(indices.tolist(), k = int(fraction*len(filenames)))\n",
    "        filenames = [filenames[i] for i in subset_indices]\n",
    "        data = [data[i] for i in subset_indices]\n",
    "        labels = [labels[i] for i in subset_indices]\n",
    "        seqs = [seqs[i] for i in subset_indices]\n",
    "        \n",
    "    return filenames, data, labels, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 256\n",
    "fileloc = '/scratch/sk7898/pedbike/'\n",
    "\n",
    "add_humans = None\n",
    "add_non_humans = ['downstream/final_bike_radial_full_cuts']    \n",
    "classes = ['Human', 'Nonhuman']\n",
    "data_labels = [0, 1]\n",
    "add_fraction = 0.1\n",
    "\n",
    "#Example filenames in stft: \n",
    "#Human_fft_8_win_14_label_0.data\n",
    "#Nonhuman_fft_96_win_24_label_1.data\n",
    "filenames = []\n",
    "data = []\n",
    "labels = []\n",
    "seqs = []\n",
    "outdir = fileloc\n",
    "\n",
    "humans_path = ['upstream/Targets/arc_1 (Humans_Gym balls)/Human/', \\\n",
    "               'upstream/Targets/bv_4 (Humans_Cars)/Human/',\\\n",
    "               'upstream/Targets/ceiling_238_10 (Humans_Gym balls)/Human/',\\\n",
    "               'upstream/Targets/combined_5 (Humans_Dogs)/11-30-2011/Human/',\\\n",
    "               'upstream/Targets/combined_5 (Humans_Dogs)/Human/',\\\n",
    "               'upstream/Targets/kh_3 (Humans_Gym balls)/Human/',\\\n",
    "               'upstream/Targets/prb_2 (Humans_Gym balls)/Human/',\\\n",
    "               'upstream/Targets/Parking garage orthogonal (Humans)/',\\\n",
    "               'upstream/Targets/Parking garage radial (Humans)/']\n",
    "\n",
    "non_humans_path = ['upstream/Targets/arc_1 (Humans_Gym balls)/Ball/',\\\n",
    "                   'upstream/Targets/bv_4 (Humans_Cars)/Car/',\\\n",
    "                   'upstream/Targets/ceiling_238_10 (Humans_Gym balls)/Ball/',\\\n",
    "                   'upstream/Targets/combined_5 (Humans_Dogs)/Dog/',\\\n",
    "                   'upstream/Targets/kh_3 (Humans_Gym balls)/Dog/',\\\n",
    "                   'upstream/Targets/prb_2 (Humans_Gym balls)/Dog/',\\\n",
    "                   'upstream/Targets/osu_farm_meadow_may24-28_2016_subset_113 (Cattle)/',\\\n",
    "                   'upstream/Targets/Radar_site1_hilltop (Cattle)/',\\\n",
    "                   'upstream/Targets/Radar_site2_creamery_subset_113 (Cattle)/']\n",
    "\n",
    "data_dirs = [humans_path, non_humans_path]\n",
    "\n",
    "for label in data_labels:\n",
    "    f, d, l, s = get_time_series_data(fileloc, data_dirs[label], label, window)\n",
    "    filenames += f\n",
    "    data += d\n",
    "    labels += l\n",
    "    seqs += s\n",
    "    \n",
    "f, d, l, s = get_time_series_data(fileloc, add_non_humans, 1, window, fraction=add_fraction)\n",
    "filenames += f \n",
    "data += d\n",
    "labels += l\n",
    "seqs += s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.2\n",
    "\n",
    "indices = np.arange(len(filenames))\n",
    "X_train, X_val, y_train, y_val, indices_train, indices_val, seqs_train, seqs_val = train_test_split(data, labels,\\\n",
    "                                                                                                    indices, seqs, \\\n",
    "                                                                                                    test_size=val_split,\\\n",
    "                                                                                                    random_state=42)\n",
    "        \n",
    "files_train = [filenames[i] for i in indices_train]\n",
    "files_val = [filenames[i] for i in indices_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the original data into train and val\n",
    "outdir = '/scratch/sk7898/pedbike/upstream'\n",
    "prefix = 'upstream'\n",
    "\n",
    "train_dir = os.path.join(outdir, prefix + \"_train\")\n",
    "val_dir = os.path.join(outdir, prefix + \"_val\")\n",
    "\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n",
    "\n",
    "train_count = 1\n",
    "for tr in files_train:\n",
    "    if labels_train[train_count-1] == 1:\n",
    "        cur_class = 'Nonhuman'\n",
    "    else:\n",
    "        cur_class = 'Human'\n",
    "    fname = cur_class +'_time_'+ str(val_count) +'_label_'+ str(y_val[val_count-1]) +'.data'\n",
    "    copy(tr, os.path.join(train_dir, cur_class, fname))\n",
    "    train_count += 1\n",
    "\n",
    "val_count = 1\n",
    "for val in files_val:\n",
    "    if labels_val[val_count-1] == 1:\n",
    "        cur_class = 'Nonhuman'\n",
    "    else:\n",
    "        cur_class = 'Human'\n",
    "    fname = cur_class +'_time_'+ str(val_count) +'_label_'+ str(y_val[val_count-1]) +'.data'\n",
    "    copy(val, os.path.join(val_dir, cur_class, fname))\n",
    "    val_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the time series data for train and val\n",
    "outdir = '/scratch/sk7898/pedbike/window_256/'\n",
    "path_prefix = 'upstream_time'\n",
    "os.makedirs(os.path.join(outdir, path_prefix), exist_ok=True)\n",
    "\n",
    "# Save train data\n",
    "np.save(os.path.join(outdir, path_prefix, \"train.npy\"), X_train)\n",
    "np.save(os.path.join(outdir, path_prefix, \"train_seqs.npy\"), seqs_train)\n",
    "np.save(os.path.join(outdir, path_prefix, \"train_lbls.npy\"), y_train)\n",
    "\n",
    "# Save validation data\n",
    "np.save(os.path.join(outdir, path_prefix, \"val.npy\"), X_val)\n",
    "np.save(os.path.join(outdir, path_prefix, \"val_seqs.npy\"), seqs_val)\n",
    "np.save(os.path.join(outdir, path_prefix, \"val_lbls.npy\"), y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
