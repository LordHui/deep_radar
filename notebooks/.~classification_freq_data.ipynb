{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import keras\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Conv2D, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection(lst1, lst2): \n",
    "    return [value for value in lst1 if value in lst2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_data(X_train, X_test, data_shape):\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_train = scaler.transform(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "    X_train = X_train.reshape(X_train.shape[0], data_shape[1], data_shape[2])\n",
    "    X_test = X_test.reshape(X_test.shape[0], data_shape[1], data_shape[2])\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_cls(labels, sel_cls):\n",
    "    \n",
    "    for i, lbl in enumerate(sel_cls):\n",
    "        labels[labels == i] = lbl\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbls_for_cls(labels, lbls_list=None):\n",
    "    new_labels = [i for i in range(len(lbls_list))]\n",
    "    for i, lbl in enumerate(lbls_list):\n",
    "        labels[labels == lbl] = new_labels[i]\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_str(sel_cls, hidden_1=64, data_mode='amp', win_len=512):\n",
    "    model_str = ''\n",
    "    for cls in sel_cls:\n",
    "        model_str += str(cls) + '_'\n",
    "    \n",
    "    model_str += data_mode + '_' + str(win_len) + '_hidden_' + str(hidden_1) \n",
    "    #model_str += '_' + str(int(validation_split*100)) if validation_split else '_None' \n",
    "    return model_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_data(data, labels, sel_cls):\n",
    "    labels_idx = []\n",
    "    for cls in sel_cls:\n",
    "        labels_idx += np.argwhere(labels == cls).flatten().tolist()\n",
    "\n",
    "    sel_labels = [labels[idx] for idx in labels_idx]\n",
    "    sel_data = [data[idx] for idx in labels_idx]\n",
    "    labels = np.array(sel_labels)\n",
    "    data = np.array(sel_data)\n",
    "    data = data.astype(np.float32) \n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downsampled_points(data, labels, target_cls=[1, 2, 3]):\n",
    "    \n",
    "    subset_idx = {}\n",
    "    downsampled_idx = []\n",
    "    \n",
    "    model_dir = '/scratch/sk7898/pedbike/models/lstm/'\n",
    "    cls_str_list = ['1_2', '1_3', '2_3']\n",
    "    sel_cls_list = [[1, 2], [1, 3], [2, 3]]\n",
    "     \n",
    "    for idx, (cls_str, sel_cls) in enumerate(zip(cls_str_list, sel_cls_list)):\n",
    "        X, y = get_cls_data(data, labels, sel_cls)\n",
    "\n",
    "        model_str = os.path.join(cls_str + '_amp_512_hidden_128/best_model.h5')\n",
    "        model_path = os.path.join(model_dir, model_str)\n",
    "\n",
    "        # Load the model to predict the count class\n",
    "        model = load_model(model_path) \n",
    "        pred = model.predict(x=X)\n",
    "        cls_pred = np.argmax(pred, axis = 1)\n",
    "        y_pred = get_true_cls(cls_pred, sel_cls)\n",
    "        \n",
    "        for cls in sel_cls:\n",
    "            if cls not in subset_idx.keys():\n",
    "                subset_idx[cls] = []\n",
    "                subset_idx[cls] = [i for i, (x, y) in enumerate(zip(y, y_pred)) if x == y]\n",
    "            else:\n",
    "                c_idx = [i for i, (x, y) in enumerate(zip(y, y_pred)) if x == y]\n",
    "                subset_idx[cls] = get_intersection(subset_idx[cls], c_idx)\n",
    "                \n",
    "    for key in subset_idx.keys():\n",
    "        downsampled_idx += subset_idx[key]\n",
    "    \n",
    "    downsampled_idx = list(dict.fromkeys(downsampled_idx))\n",
    "    sel_labels = [labels[idx] for idx in downsampled_idx]\n",
    "    sel_data = [data[idx] for idx in downsampled_idx]\n",
    "    labels = np.array(sel_labels)\n",
    "    data = np.array(sel_data).astype(np.float32) \n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sel_cls,\n",
    "             data_mode='amp', \n",
    "             task_type='cls',\n",
    "             downsample=True,\n",
    "             scaling=True):\n",
    "    \n",
    "    data_dir = '/scratch/sk7898/pedbike/fft_data'\n",
    "    data_path = os.path.join(data_dir, 'Data_win_fft.npy')\n",
    "    labels_path = os.path.join(data_dir, 'label_win_fft.npy')\n",
    "    seqs_path = os.path.join(data_dir, 'seqs_fft.npy')\n",
    "    data = np.load(data_path, allow_pickle=True) #shape: (18642, 256, 5)\n",
    "    labels = np.load(labels_path, allow_pickle=True) #shape: (18642,)\n",
    "\n",
    "    n_data = data.swapaxes(1, 2)\n",
    "    amp_data = np.absolute(n_data)\n",
    "    phase_data = np.angle(n_data)\n",
    "    power_data = np.absolute(n_data)**2\n",
    "    real_data = np.real(n_data)\n",
    "    imag_data = np.imag(n_data)\n",
    "    \n",
    "    if data_mode == 'amp':\n",
    "        data = amp_data\n",
    "    elif data_mode == 'phase':\n",
    "        data = phase_data\n",
    "    elif data_mode == 'power':\n",
    "        data == power_data\n",
    "\n",
    "    data, labels = get_cls_data(data, labels, sel_cls)\n",
    "\n",
    "    if downsample:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                            labels,\n",
    "                                                            test_size=0.1,\n",
    "                                                            random_state=42)\n",
    "        if scaling:\n",
    "            X_train, X_test = get_scaled_data(X_train, X_test, data_shape=n_data.shape)\n",
    "        \n",
    "        X_train, y_train = get_downsampled_points(X_train,\n",
    "                                                  y_train,\n",
    "                                                  target_cls=sel_cls)\n",
    "                \n",
    "        y_train = lbls_for_cls(y_train, lbls_list=sel_cls)\n",
    "        y_test = lbls_for_cls(y_test, lbls_list=sel_cls)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    else:\n",
    "        labels = lbls_for_cls(labels, lbls_list=sel_cls)\n",
    "        labels = labels.reshape(-1, 1)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                            labels,\n",
    "                                                            test_size=0.1,\n",
    "                                                            random_state=42)\n",
    "    \n",
    "        if scaling:\n",
    "            X_train, X_test = get_scaled_data(X_train, X_test, data_shape=n_data.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_fft_model(hidden_1,\n",
    "                         counting_dense_1,\n",
    "                         counting_dense_2,\n",
    "                         kernel_initializer='normal',\n",
    "                         dropout_1=None,\n",
    "                         dropout_2=None,\n",
    "                         optimizer=None,\n",
    "                         input_shape=(5, 256),\n",
    "                         n_classes=2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_1, return_sequences=False, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(counting_dense_1, activation='relu', name='counting_dense_1'))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(counting_dense_2, activation='relu', name='counting_dense_2'))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(n_classes, activation='softmax', name='output'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv2d_fft_model(filters_1,\n",
    "                           counting_dense_1,\n",
    "                           counting_dense_2,\n",
    "                           kernel_initializer='normal',\n",
    "                           dropout=None,\n",
    "                           optimizer=None,\n",
    "                           input_shape=(5, 256, 1),\n",
    "                           task_type=None,\n",
    "                           n_classes=2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters_1, kernel_size=(2, 8), strides=(1, 8), data_format='channels_last', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(counting_dense_1, activation='relu', name='counting_dense_1'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(counting_dense_2, activation='relu', name='counting_dense_2'))\n",
    "    model.add(Dense(n_classes, activation='softmax', name='output'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4092 samples, validate on 455 samples\n",
      "Epoch 1/60\n",
      "4092/4092 [==============================] - 2s 372us/step - loss: 1.1980 - sparse_categorical_accuracy: 0.3829 - val_loss: 1.0461 - val_sparse_categorical_accuracy: 0.4681\n",
      "Epoch 2/60\n",
      "4092/4092 [==============================] - 1s 201us/step - loss: 1.0950 - sparse_categorical_accuracy: 0.4379 - val_loss: 1.0141 - val_sparse_categorical_accuracy: 0.5429\n",
      "Epoch 3/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 1.0337 - sparse_categorical_accuracy: 0.4751 - val_loss: 0.9821 - val_sparse_categorical_accuracy: 0.5604\n",
      "Epoch 4/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.9960 - sparse_categorical_accuracy: 0.5056 - val_loss: 0.9511 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 5/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.9574 - sparse_categorical_accuracy: 0.5191 - val_loss: 0.9210 - val_sparse_categorical_accuracy: 0.5912\n",
      "Epoch 6/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.9148 - sparse_categorical_accuracy: 0.5572 - val_loss: 0.9054 - val_sparse_categorical_accuracy: 0.5692\n",
      "Epoch 7/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.8997 - sparse_categorical_accuracy: 0.5709 - val_loss: 0.8854 - val_sparse_categorical_accuracy: 0.5846\n",
      "Epoch 8/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.8768 - sparse_categorical_accuracy: 0.5914 - val_loss: 0.8784 - val_sparse_categorical_accuracy: 0.5868\n",
      "Epoch 9/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.8409 - sparse_categorical_accuracy: 0.6065 - val_loss: 0.8711 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.8250 - sparse_categorical_accuracy: 0.6227 - val_loss: 0.8626 - val_sparse_categorical_accuracy: 0.5868\n",
      "Epoch 11/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.8101 - sparse_categorical_accuracy: 0.6344 - val_loss: 0.8589 - val_sparse_categorical_accuracy: 0.5846\n",
      "Epoch 12/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.7912 - sparse_categorical_accuracy: 0.6354 - val_loss: 0.8531 - val_sparse_categorical_accuracy: 0.5868\n",
      "Epoch 13/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.7635 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.8535 - val_sparse_categorical_accuracy: 0.6022\n",
      "Epoch 14/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.7570 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.8455 - val_sparse_categorical_accuracy: 0.6044\n",
      "Epoch 15/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.7223 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.8321 - val_sparse_categorical_accuracy: 0.6044\n",
      "Epoch 16/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.7008 - sparse_categorical_accuracy: 0.6977 - val_loss: 0.8338 - val_sparse_categorical_accuracy: 0.6066\n",
      "Epoch 17/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.6920 - sparse_categorical_accuracy: 0.7099 - val_loss: 0.8189 - val_sparse_categorical_accuracy: 0.6154\n",
      "Epoch 18/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.6559 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.8227 - val_sparse_categorical_accuracy: 0.6264\n",
      "Epoch 19/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.6394 - sparse_categorical_accuracy: 0.7270 - val_loss: 0.8280 - val_sparse_categorical_accuracy: 0.6088\n",
      "Epoch 20/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.6114 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.8273 - val_sparse_categorical_accuracy: 0.6088\n",
      "Epoch 21/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.5853 - sparse_categorical_accuracy: 0.7622 - val_loss: 0.8369 - val_sparse_categorical_accuracy: 0.6198\n",
      "Epoch 22/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.5771 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.8327 - val_sparse_categorical_accuracy: 0.6264\n",
      "Epoch 23/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.5453 - sparse_categorical_accuracy: 0.7813 - val_loss: 0.8292 - val_sparse_categorical_accuracy: 0.6330\n",
      "Epoch 24/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.5313 - sparse_categorical_accuracy: 0.7852 - val_loss: 0.8446 - val_sparse_categorical_accuracy: 0.6352\n",
      "Epoch 25/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.5001 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.8453 - val_sparse_categorical_accuracy: 0.6264\n",
      "Epoch 26/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.4932 - sparse_categorical_accuracy: 0.8023 - val_loss: 0.8581 - val_sparse_categorical_accuracy: 0.6242\n",
      "Epoch 27/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.4726 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.8459 - val_sparse_categorical_accuracy: 0.6308\n",
      "Epoch 28/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.8443 - val_sparse_categorical_accuracy: 0.6330\n",
      "Epoch 29/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.4299 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.8695 - val_sparse_categorical_accuracy: 0.6505\n",
      "Epoch 30/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.4074 - sparse_categorical_accuracy: 0.8421 - val_loss: 0.8682 - val_sparse_categorical_accuracy: 0.6527\n",
      "Epoch 31/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.3925 - sparse_categorical_accuracy: 0.8463 - val_loss: 0.8869 - val_sparse_categorical_accuracy: 0.6527\n",
      "Epoch 32/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.3672 - sparse_categorical_accuracy: 0.8602 - val_loss: 0.9004 - val_sparse_categorical_accuracy: 0.6571\n",
      "Epoch 33/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.3617 - sparse_categorical_accuracy: 0.8524 - val_loss: 0.9226 - val_sparse_categorical_accuracy: 0.6549\n",
      "Epoch 34/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.3298 - sparse_categorical_accuracy: 0.8741 - val_loss: 0.9176 - val_sparse_categorical_accuracy: 0.6637\n",
      "Epoch 35/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.3015 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.9542 - val_sparse_categorical_accuracy: 0.6484\n",
      "Epoch 36/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.2993 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.9964 - val_sparse_categorical_accuracy: 0.6484\n",
      "Epoch 37/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.2861 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.9746 - val_sparse_categorical_accuracy: 0.6659\n",
      "Epoch 38/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.2566 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.9912 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 39/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.2498 - sparse_categorical_accuracy: 0.9069 - val_loss: 1.0118 - val_sparse_categorical_accuracy: 0.6571\n",
      "Epoch 40/60\n",
      "4092/4092 [==============================] - 1s 203us/step - loss: 0.2418 - sparse_categorical_accuracy: 0.9110 - val_loss: 0.9994 - val_sparse_categorical_accuracy: 0.6923\n",
      "Epoch 41/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.2144 - sparse_categorical_accuracy: 0.9196 - val_loss: 1.0383 - val_sparse_categorical_accuracy: 0.6593\n",
      "Epoch 42/60\n",
      "4092/4092 [==============================] - 1s 198us/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9218 - val_loss: 1.0409 - val_sparse_categorical_accuracy: 0.6703\n",
      "Epoch 43/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1916 - sparse_categorical_accuracy: 0.9318 - val_loss: 1.0719 - val_sparse_categorical_accuracy: 0.6813\n",
      "Epoch 44/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.1813 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.0693 - val_sparse_categorical_accuracy: 0.6769\n",
      "Epoch 45/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1725 - sparse_categorical_accuracy: 0.9372 - val_loss: 1.1147 - val_sparse_categorical_accuracy: 0.6659\n",
      "Epoch 46/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9457 - val_loss: 1.1730 - val_sparse_categorical_accuracy: 0.6703\n",
      "Epoch 47/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9555 - val_loss: 1.1151 - val_sparse_categorical_accuracy: 0.6857\n",
      "Epoch 48/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1433 - sparse_categorical_accuracy: 0.9506 - val_loss: 1.1776 - val_sparse_categorical_accuracy: 0.6835\n",
      "Epoch 49/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1317 - sparse_categorical_accuracy: 0.9550 - val_loss: 1.1837 - val_sparse_categorical_accuracy: 0.6681\n",
      "Epoch 50/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1359 - sparse_categorical_accuracy: 0.9516 - val_loss: 1.2170 - val_sparse_categorical_accuracy: 0.6681\n",
      "Epoch 51/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9611 - val_loss: 1.2362 - val_sparse_categorical_accuracy: 0.6681\n",
      "Epoch 52/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9643 - val_loss: 1.2274 - val_sparse_categorical_accuracy: 0.6857\n",
      "Epoch 53/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9707 - val_loss: 1.3253 - val_sparse_categorical_accuracy: 0.6791\n",
      "Epoch 54/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9739 - val_loss: 1.3375 - val_sparse_categorical_accuracy: 0.6725\n",
      "Epoch 55/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9748 - val_loss: 1.4170 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 56/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.4159 - val_sparse_categorical_accuracy: 0.6659\n",
      "Epoch 57/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9831 - val_loss: 1.3704 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 58/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9743 - val_loss: 1.3602 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 59/60\n",
      "4092/4092 [==============================] - 1s 200us/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9804 - val_loss: 1.4214 - val_sparse_categorical_accuracy: 0.6835\n",
      "Epoch 60/60\n",
      "4092/4092 [==============================] - 1s 199us/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9792 - val_loss: 1.4761 - val_sparse_categorical_accuracy: 0.6615\n",
      "1294/1294 [==============================] - 0s 68us/step\n",
      "Accuracy: 0.7117465138435364 MAE: 0.34853168469860896\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "dropout_1 = 0.3\n",
    "dropout_2 = 0.3\n",
    "hidden_1 = 128\n",
    "filters_1 = 64\n",
    "counting_dense_1 = 256\n",
    "counting_dense_2 = 64\n",
    "\n",
    "cls_list = [[1, 2, 3]] #[2, 4], [1, 2, 3], [1, 2, 3, 4]\n",
    "model_type = 'lstm'\n",
    "data_mode = 'amp'\n",
    "model_dir = '/scratch/sk7898/pedbike/models'\n",
    "downsample = True\n",
    "\n",
    "for sel_cls in cls_list:\n",
    "    model_str = get_model_str(sel_cls, hidden_1=hidden_1, data_mode='amp', win_len=512)\n",
    "    model_path = os.path.join(model_dir, model_type, model_str)\n",
    "    \n",
    "    if not os.path.isdir(model_path):\n",
    "        os.makedirs(model_path)\n",
    "                \n",
    "    X_train, X_test, y_train, y_test = get_data(sel_cls=sel_cls,\n",
    "                                                data_mode='amp',\n",
    "                                                downsample=downsample)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    if model_type == 'conv':\n",
    "        X_train = X_train[:, :, :, np.newaxis]\n",
    "        X_test = X_test[:, :, :, np.newaxis]\n",
    "    \n",
    "        model = build_conv2d_fft_model(filters_1,\n",
    "                                       counting_dense_1,\n",
    "                                       counting_dense_2,\n",
    "                                       dropout_1=dropout_1,\n",
    "                                       optimizer=optimizer,\n",
    "                                       n_classes=len(sel_cls),\n",
    "                                       input_shape=(5, 256, 1))\n",
    "    else:\n",
    "        model = build_lstm_fft_model(hidden_1,\n",
    "                                     counting_dense_1,\n",
    "                                     counting_dense_2,\n",
    "                                     dropout_1=dropout_1,\n",
    "                                     dropout_2=dropout_2,\n",
    "                                     optimizer=optimizer,\n",
    "                                     input_shape=(5, 256),\n",
    "                                     n_classes=len(sel_cls))    \n",
    "    \n",
    "    H_train = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.1,\n",
    "                        epochs=epochs,\n",
    "                        shuffle=True)\n",
    "    \n",
    "    \n",
    "    model.save(os.path.join(model_path, 'latest_model_downsample.h5'))\n",
    "    evaluations = model.evaluate(x=X_test, y=y_test)    \n",
    "    pred = model.predict(x=X_test)\n",
    "    cls_pred = np.argmax(pred, axis = 1)\n",
    "    mae = mean_absolute_error(y_test, cls_pred)\n",
    "    print('Accuracy: {} MAE: {}'.format(evaluations[1], mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
