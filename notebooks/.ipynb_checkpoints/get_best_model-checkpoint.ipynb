{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import types\n",
    "import random\n",
    "import argparse\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_loss(model_base_path, x_test, y_test):\n",
    "    \n",
    "    loss_list = []\n",
    "    file_list = os.listdir(model_base_path)\n",
    "    if 'best_val_loss_model.h5' in file_list:\n",
    "        print('Testing 1 model')\n",
    "        model_path = os.path.join(model_base_path, 'best_val_loss_model.h5')\n",
    "        model = load_model(model_path)\n",
    "        model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['mae'])\n",
    "        test_gen = val_generator(x_test, y_test)\n",
    "        loss = model.evaluate_generator(test_gen, steps=len(test_gen))\n",
    "        loss_list.append({'file': file, 'loss': loss[0], 'mae': loss[1]}) \n",
    "    else:\n",
    "        for file in file_list:\n",
    "            if 'csv' in file:\n",
    "                continue\n",
    "            model_path = os.path.join(model_base_path, file, 'best_val_loss_model.h5')\n",
    "            if 'lr' in file:\n",
    "                lr_idx = file.rindex('lr')\n",
    "                learning_rate = float(file[lr_idx+3:file.rindex('|')])\n",
    "            else:\n",
    "                learning_rate = 0.0001\n",
    "            model = load_model(model_path)\n",
    "            model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=learning_rate), metrics=['mae'])\n",
    "            test_gen = val_generator(x_test, y_test)\n",
    "            loss = model.evaluate_generator(test_gen, steps=len(test_gen))\n",
    "            loss_list.append({'file': file, 'loss': loss[0], 'mae': loss[1]})        \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction(model_dir, x_test, y_test):\n",
    "\n",
    "    model_path = os.path.join(model_dir, 'best_val_loss_model.h5')\n",
    "    model = load_model(model_path)\n",
    "    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['mae'])\n",
    "    test_gen = val_generator(x_test, y_test)\n",
    "    predictions = model.predict_generator(test_gen, steps=len(test_gen))\n",
    "        \n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For stft count_dense1 = 128\n",
    "#Best: -1.2366702235959561 using {'count_dense1': 128, 'count_dense2': 16, 'count_hidden1': 64, 'dropout': 0.2, 'epochs': 50, 'hidden1': 32, 'init': 'normal', 'lr': 0.0001, 'optimizer': 'adam'}\n",
    "data_type = 'time'\n",
    "data_base_path = '/scratch/sk7898/pedbike/window_256'\n",
    "best_model = 'count_dense1=64|count_dense2=16|count_hidden1=32|hidden1=64'\n",
    "\n",
    "if data_type == 'stft':\n",
    "    model_base_path = '/scratch/sk7898/radar_counting/models/lstm_stft'\n",
    "    fileloc = os.path.join(data_base_path, 'downstream_stft')\n",
    "elif data_type == 'time':\n",
    "    model_base_path = '/scratch/sk7898/radar_counting/models/lstm_time'\n",
    "    fileloc = os.path.join(data_base_path, 'downstream_time')\n",
    "else:\n",
    "    raise ValueError('Data type not supported!')\n",
    "    \n",
    "model_path = os.path.join(model_base_path, best_model)\n",
    "x_train, x_val, x_test, y_train, y_val, y_test, seqs_train, seqs_val, seqs_test = get_data(fileloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = get_model_loss(model_path, x_test, y_test)\n",
    "print(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1938884]\n",
      " [2.1851707]\n",
      " [2.1765296]\n",
      " [2.1703002]\n",
      " [2.187777 ]\n",
      " [2.1821437]\n",
      " [2.1786397]\n",
      " [2.1838152]\n",
      " [2.1825333]\n",
      " [2.1833713]\n",
      " [2.1812406]\n",
      " [2.1847894]\n",
      " [2.1796305]\n",
      " [2.189432 ]\n",
      " [2.188066 ]\n",
      " [2.178646 ]\n",
      " [2.178604 ]\n",
      " [2.1855125]\n",
      " [2.1791244]\n",
      " [2.1841063]\n",
      " [2.1897428]\n",
      " [2.1801343]\n",
      " [2.1814184]\n",
      " [2.1896682]\n",
      " [2.1903288]\n",
      " [2.178945 ]\n",
      " [2.1851506]\n",
      " [2.1795402]\n",
      " [2.181309 ]\n",
      " [2.1784322]\n",
      " [2.1903834]\n",
      " [2.1760602]\n",
      " [2.1791923]\n",
      " [2.1790123]\n",
      " [2.1821125]\n",
      " [2.1796112]\n",
      " [2.1809201]\n",
      " [2.1789713]\n",
      " [2.1812344]\n",
      " [2.193906 ]\n",
      " [2.1776106]\n",
      " [2.1792014]\n",
      " [2.1825385]\n",
      " [2.177925 ]\n",
      " [2.1838446]\n",
      " [2.178438 ]\n",
      " [2.1808608]\n",
      " [2.179047 ]\n",
      " [2.1927092]\n",
      " [2.178223 ]\n",
      " [2.17806  ]\n",
      " [2.1776273]\n",
      " [2.1791666]\n",
      " [2.1819766]\n",
      " [2.176402 ]\n",
      " [2.1791189]\n",
      " [2.1846566]\n",
      " [2.1756952]\n",
      " [2.179805 ]\n",
      " [2.1892962]\n",
      " [2.1928377]\n",
      " [2.1779919]\n",
      " [2.1802113]\n",
      " [2.1864772]\n",
      " [2.183382 ]\n",
      " [2.179324 ]\n",
      " [2.1788485]\n",
      " [2.180514 ]\n",
      " [2.1794214]\n",
      " [2.1813946]\n",
      " [2.1914454]\n",
      " [2.1896718]\n",
      " [2.1806152]\n",
      " [2.178083 ]\n",
      " [2.178766 ]\n",
      " [2.177303 ]\n",
      " [2.1822422]\n",
      " [2.1813946]\n",
      " [2.1796627]\n",
      " [2.1828523]\n",
      " [2.1915958]\n",
      " [2.1788812]\n",
      " [2.1791608]\n",
      " [2.1837904]\n",
      " [2.1774664]\n",
      " [2.181704 ]\n",
      " [2.1807597]\n",
      " [2.1793032]\n",
      " [2.1807816]\n",
      " [2.1817775]\n",
      " [2.1767995]\n",
      " [2.182461 ]\n",
      " [2.191601 ]\n",
      " [2.1824431]\n",
      " [2.1802864]\n",
      " [2.1797183]]\n"
     ]
    }
   ],
   "source": [
    "predictions = get_model_prediction(model_path, x_test, y_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
