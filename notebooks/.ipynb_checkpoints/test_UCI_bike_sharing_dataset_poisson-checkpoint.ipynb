{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#copied from https://github.com/haydarozler/bike-sharing-prediction-with-RNN/blob/master/BikeSharing-V3.ipynb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, RNN, SimpleRNN, Dropout\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Activation\n",
    "from keras.callbacks import LambdaCallback\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_data(data):\n",
    "    in_seq1 = array(datatrain['holiday'])\n",
    "    in_seq2 = array(datatrain['workingday'])\n",
    "    in_seq3 = array(datatrain['temp'])\n",
    "    in_seq4 = array(datatrain['atemp'])\n",
    "    in_seq5 = array(datatrain['hum'])\n",
    "    in_seq6 = array(datatrain['windspeed'])\n",
    "    in_seq7 = array(datatrain['weekday_0'])\n",
    "    in_seq8 = array(datatrain['weekday_1'])\n",
    "    in_seq9 = array(datatrain['weekday_2'])\n",
    "    in_seq10 = array(datatrain['weekday_3'])\n",
    "    in_seq11 = array(datatrain['weekday_4'])\n",
    "    in_seq12 = array(datatrain['weekday_5'])\n",
    "    in_seq13 = array(datatrain['weekday_6'])\n",
    "    in_seq14 = array(datatrain['weathersit_1'])\n",
    "    in_seq15 = array(datatrain['weathersit_2'])\n",
    "    in_seq16 = array(datatrain['weathersit_3'])\n",
    "    out_seq = array(datatrain['cntscl'])\n",
    "    \n",
    "    in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "    in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "    in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "    in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "    in_seq5 = in_seq5.reshape((len(in_seq5), 1))\n",
    "    in_seq6 = in_seq6.reshape((len(in_seq6), 1))\n",
    "    in_seq7 = in_seq7.reshape((len(in_seq7), 1))\n",
    "    in_seq8 = in_seq8.reshape((len(in_seq8), 1))\n",
    "    in_seq9 = in_seq9.reshape((len(in_seq9), 1))\n",
    "    in_seq10 = in_seq10.reshape((len(in_seq10), 1))\n",
    "    in_seq11 = in_seq11.reshape((len(in_seq11), 1))\n",
    "    in_seq12 = in_seq12.reshape((len(in_seq12), 1))\n",
    "    in_seq13 = in_seq13.reshape((len(in_seq13), 1))\n",
    "    in_seq14 = in_seq14.reshape((len(in_seq14), 1))\n",
    "    in_seq15 = in_seq15.reshape((len(in_seq15), 1))\n",
    "    in_seq16 = in_seq16.reshape((len(in_seq16), 1))\n",
    "    out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "    \n",
    "    data_feed = hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5, in_seq6, in_seq7, in_seq8, in_seq9, in_seq10, in_seq11, in_seq12, in_seq13, in_seq14, in_seq15, in_seq16, out_seq))\n",
    "    return data_feed, out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/uci_bike_sharing/day.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(dataset['weekday'], prefix='weekday')\n",
    "dataset = dataset.join(one_hot)\n",
    "one_hot = pd.get_dummies(dataset['weathersit'], prefix='weathersit')\n",
    "dataset = dataset.join(one_hot)\n",
    "one_hot = pd.get_dummies(dataset['mnth'], prefix='mnth')\n",
    "dataset = dataset.join(one_hot)\n",
    "\n",
    "#scale the counts \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(array(dataset['cnt']).reshape(len(dataset['cnt']), 1))\n",
    "series = pd.DataFrame(scaled)\n",
    "series.columns = ['cntscl']\n",
    "dataset = pd.merge(dataset, series, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total, Train, Val, Test: 731 631 50 50\n"
     ]
    }
   ],
   "source": [
    "number_of_test_data = 50\n",
    "number_of_holdout_data = 50\n",
    "number_of_training_data = len(dataset) - number_of_holdout_data - number_of_test_data\n",
    "print (\"Total, Train, Val, Test:\", len(dataset), number_of_training_data, number_of_test_data, number_of_holdout_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain = dataset[:number_of_training_data]\n",
    "datatest = dataset[-(number_of_test_data+number_of_holdout_data):-number_of_holdout_data]\n",
    "datahold = dataset[-number_of_holdout_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain_feed, out_seq_train = get_3d_data(datatrain)\n",
    "datatest_feed, out_seq_test = get_3d_data(datatest)\n",
    "datahold_feed, out_seq_hold = get_3d_data(datahold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = datatrain_feed.shape[1]\n",
    "n_input = 10\n",
    "generator_train = TimeseriesGenerator(datatrain_feed, out_seq_train, length=n_input, batch_size=len(datatrain_feed))\n",
    "generator_test = TimeseriesGenerator(datatest_feed, out_seq_test, length=n_input, batch_size=1)\n",
    "generator_hold = TimeseriesGenerator(datahold_feed, out_seq_hold, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps, Features: 10 17\n"
     ]
    }
   ],
   "source": [
    "datatest.head()\n",
    "print(\"Timesteps, Features:\", n_input, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(4, activation='relu', input_shape=(n_input, n_features), return_sequences = False))\n",
    "model.add(Dense(1, activation='softplus'))\n",
    "model.compile(optimizer=adam, loss='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/sk7898/miniconda3/envs/l3embedding-tf-14-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      " - 26s - loss: 0.9358 - val_loss: 1.0542\n",
      "Epoch 2/20\n",
      " - 22s - loss: 0.9355 - val_loss: 1.0543\n",
      "Epoch 3/20\n",
      " - 15s - loss: 0.9353 - val_loss: 1.0544\n",
      "Epoch 4/20\n",
      " - 44s - loss: 0.9351 - val_loss: 1.0544\n",
      "Epoch 5/20\n",
      " - 50s - loss: 0.9349 - val_loss: 1.0545\n",
      "Epoch 6/20\n",
      " - 15s - loss: 0.9347 - val_loss: 1.0546\n",
      "Epoch 7/20\n",
      " - 23s - loss: 0.9345 - val_loss: 1.0547\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.9343 - val_loss: 1.0547\n",
      "Epoch 9/20\n",
      " - 24s - loss: 0.9341 - val_loss: 1.0548\n",
      "Epoch 10/20\n",
      " - 26s - loss: 0.9339 - val_loss: 1.0549\n",
      "Epoch 11/20\n",
      " - 14s - loss: 0.9337 - val_loss: 1.0550\n",
      "Epoch 12/20\n",
      " - 16s - loss: 0.9334 - val_loss: 1.0551\n",
      "Epoch 13/20\n",
      " - 7s - loss: 0.9332 - val_loss: 1.0551\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.9330 - val_loss: 1.0552\n",
      "Epoch 15/20\n",
      " - 18s - loss: 0.9328 - val_loss: 1.0553\n",
      "Epoch 16/20\n",
      " - 17s - loss: 0.9326 - val_loss: 1.0553\n",
      "Epoch 17/20\n",
      " - 14s - loss: 0.9324 - val_loss: 1.0554\n",
      "Epoch 18/20\n",
      " - 12s - loss: 0.9322 - val_loss: 1.0555\n",
      "Epoch 19/20\n",
      " - 18s - loss: 0.9320 - val_loss: 1.0556\n",
      "Epoch 20/20\n",
      " - 33s - loss: 0.9318 - val_loss: 1.0556\n"
     ]
    }
   ],
   "source": [
    "score = model.fit_generator(generator_train, epochs=20, verbose=2, validation_data=generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7228652]\n"
     ]
    }
   ],
   "source": [
    "test_score = model.predict_generator(generator_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=0.7228652238845825.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-28e8c6bc3410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Actual'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Prediction'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatahold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatahold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cnt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sk7898/miniconda3/envs/l3embedding-tf-14-cpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 404\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sk7898/miniconda3/envs/l3embedding-tf-14-cpu/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=0.7228652238845825.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})\n",
    "for i in range(len(datahold)):\n",
    "    df_result = df_result.append({'Actual': datahold.iloc[i]['cnt'], 'Prediction': scaler.inverse_transform(test_score[i][0])}, ignore_index=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
