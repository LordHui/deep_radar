{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import types\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_embedding_model(hidden_1, hidden_2,\\\n",
    "                         num_layers=1, reshape=None):\n",
    "    global input_shape\n",
    "    model = Sequential()\n",
    "    if reshape:\n",
    "        model.add(Reshape(reshape, input_shape=input_shape))\n",
    "        model.add(LSTM(hidden_1, return_sequences=True))\n",
    "    else:\n",
    "        model.add(LSTM(hidden_1, return_sequences=True, input_shape=input_shape))\n",
    "    if num_layers == 2:\n",
    "        model.add(LSTM(hidden_2, return_sequences=True, input_shape=input_shape))\n",
    "    return model\n",
    "\n",
    "def lstm_counting_model(model, counting_hidden_1, counting_dense_1,\\\n",
    "                        counting_dense_2, kernel_initializer='normal',\\\n",
    "                        optimizer=None, learning_rate=0.001, dropout=None):\n",
    "    \n",
    "    if optimizer == 'adam' or optimizer is None:\n",
    "        adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "    \n",
    "    model.add(Masking(mask_value=0.0, name='mask'))\n",
    "    model.add(LSTM(counting_hidden_1, return_sequences=False, name='counting_lstm_1'))\n",
    "    model.add(Dense(counting_dense_1, activation='relu', kernel_initializer=kernel_initializer, name='counting_dense_1'))\n",
    "    model.add(Dense(counting_dense_2, activation='relu', kernel_initializer=kernel_initializer, name='counting_dense_2'))\n",
    "    model.add(Dense(1, kernel_initializer=kernel_initializer, name='output'))\n",
    "    model.add(Activation('softplus'))\n",
    "    model.compile(loss='poisson', optimizer=adam, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def build_lstm_time_model(hidden_1, hidden_2, counting_hidden_1,\\\n",
    "                          counting_dense_1, counting_dense_2,\\\n",
    "                          kernel_initializer='normal',\\\n",
    "                          learning_rate=1e-2, optimizer='adam', dropout=None):\n",
    "    \n",
    "    model = lstm_embedding_model(hidden_1, hidden_2, reshape=(-1, 2))\n",
    "    counting_model = lstm_counting_model(model, counting_hidden_1,\\\n",
    "                                         counting_dense_1, counting_dense_2,\\\n",
    "                                         kernel_initializer=kernel_initializer,\\\n",
    "                                         optimizer=optimizer, learning_rate=learning_rate, dropout=dropout)\n",
    "    return counting_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    data_type = 'time'\n",
    "    window = 256\n",
    "    loss = 'poisson'\n",
    "    model_type = 'lstm_time'\n",
    "    base_path = '/scratch/sk7898/pedbike/window_256'\n",
    "    batch_size = 64\n",
    "\n",
    "if data_type == 'stft':\n",
    "    fileloc = os.path.join(base_path, 'downstream_stft')\n",
    "elif data_type == 'time':\n",
    "    fileloc = os.path.join(base_path, 'downstream_time')\n",
    "else:\n",
    "    raise ValueError('Only stft/time are valid data types')\n",
    "    \n",
    "x_train, x_val, x_test, y_train, y_val, y_test, seqs_train, seqs_val, seqs_test = get_data(fileloc)\n",
    "n_bins = int(len(seqs_train)/batch_size)\n",
    "    \n",
    "assert x_train.shape[0] == y_train.shape[0] == seqs_train.shape[0]    \n",
    "\n",
    "n_timesteps, n_features = None, window*2\n",
    "input_shape=(n_timesteps, n_features)\n",
    "\n",
    "train_gen = train_generator(n_bins, x_train, y_train, seq_lengths=seqs_train, padding=True, padding_value=0.0)\n",
    "val_gen = val_generator(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/12 [==========================>...] - ETA: 6s - loss: 1.5203 - mean_absolute_error: 1.5644 Epoch 00001: val_loss improved from inf to 1.05871, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 87s 7s/step - loss: 1.5418 - mean_absolute_error: 1.6241 - val_loss: 1.0587 - val_mean_absolute_error: 0.3047\n",
      "Epoch 2/10\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.5718 - mean_absolute_error: 1.7213 Epoch 00002: val_loss improved from 1.05871 to 1.05709, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: 1.5355 - mean_absolute_error: 1.6212 - val_loss: 1.0571 - val_mean_absolute_error: 0.3010\n",
      "Epoch 3/10\n",
      "11/12 [==========================>...] - ETA: 6s - loss: 1.4870 - mean_absolute_error: 1.5029 Epoch 00003: val_loss improved from 1.05709 to 1.05560, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 85s 7s/step - loss: 1.5293 - mean_absolute_error: 1.6186 - val_loss: 1.0556 - val_mean_absolute_error: 0.2975\n",
      "Epoch 4/10\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.5414 - mean_absolute_error: 1.6669 Epoch 00004: val_loss improved from 1.05560 to 1.05411, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: 1.5230 - mean_absolute_error: 1.6157 - val_loss: 1.0541 - val_mean_absolute_error: 0.2939\n",
      "Epoch 5/10\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.5346 - mean_absolute_error: 1.6637 Epoch 00005: val_loss improved from 1.05411 to 1.05239, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 86s 7s/step - loss: 1.5163 - mean_absolute_error: 1.6125 - val_loss: 1.0524 - val_mean_absolute_error: 0.2898\n",
      "Epoch 6/10\n",
      "11/12 [==========================>...] - ETA: 6s - loss: 1.5077 - mean_absolute_error: 1.6036 Epoch 00006: val_loss improved from 1.05239 to 1.05021, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: 1.5085 - mean_absolute_error: 1.6090 - val_loss: 1.0502 - val_mean_absolute_error: 0.2844\n",
      "Epoch 7/10\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.5162 - mean_absolute_error: 1.6558 Epoch 00007: val_loss improved from 1.05021 to 1.04764, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: 1.4982 - mean_absolute_error: 1.6043 - val_loss: 1.0476 - val_mean_absolute_error: 0.2778\n",
      "Epoch 8/10\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.5202 - mean_absolute_error: 1.6990 Epoch 00008: val_loss improved from 1.04764 to 1.04396, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 85s 7s/step - loss: 1.4868 - mean_absolute_error: 1.5983 - val_loss: 1.0440 - val_mean_absolute_error: 0.2680\n",
      "Epoch 9/10\n",
      "11/12 [==========================>...] - ETA: 5s - loss: 1.4241 - mean_absolute_error: 1.4724 Epoch 00009: val_loss improved from 1.04396 to 1.03923, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: 1.4680 - mean_absolute_error: 1.5899 - val_loss: 1.0392 - val_mean_absolute_error: 0.2546\n",
      "Epoch 10/10\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.4468 - mean_absolute_error: 1.5832 Epoch 00010: val_loss improved from 1.03923 to 1.03331, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20191217082211/best_val_loss_model.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: 1.4457 - mean_absolute_error: 1.5778 - val_loss: 1.0333 - val_mean_absolute_error: 0.2364\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "lr = 1e-4\n",
    "optimizer = 'adam'\n",
    "dropout = 0.2\n",
    "hidden_1 = 64\n",
    "hidden_2 = 32\n",
    "counting_hidden_1 = 32\n",
    "counting_dense_1 = 64\n",
    "counting_dense_2 = 16\n",
    "\n",
    "output_path = os.path.join('/scratch/sk7898/radar_counting/models/' + loss, model_type, datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "#Callbacks for the training\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, min_delta=1e-4, verbose=5, mode=\"auto\")\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)        \n",
    "model_checkpoint = ModelCheckpoint(os.path.join(output_path, 'best_val_loss_model.h5'),\\\n",
    "                                   monitor=\"val_loss\", verbose=5, save_best_only=True, mode=\"auto\")\n",
    "callbacks = [early_stopping, reduce_LR, model_checkpoint]\n",
    "        \n",
    "model = build_lstm_time_model(hidden_1, hidden_2, counting_hidden_1,\\\n",
    "                              counting_dense_1, counting_dense_2,\\\n",
    "                              learning_rate=lr, optimizer=optimizer, dropout=dropout)\n",
    "\n",
    "H_train = model.fit_generator(train_gen, validation_data=val_gen, validation_steps=1,\\\n",
    "                              steps_per_epoch=n_bins, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Test:  [[0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.7635876 ]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]\n",
      " [0.76358783]]\n"
     ]
    }
   ],
   "source": [
    "#predicted_train = model.predict_generator(train_gen, steps=int(len(seqs_train)/batch_size))\n",
    "#print('Predicted Train: ', predicted_train)\n",
    "test_gen = test_generator(x_test, y_test)\n",
    "predicted_test = model.predict_generator(test_gen, steps=len(seqs_test))\n",
    "print('Predicted Test: ', predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4069990118344624\n",
      "MAE: 1.6218287870287895\n"
     ]
    }
   ],
   "source": [
    "test_gen = val_generator(x_test, y_test)\n",
    "H_evaluate = model.evaluate_generator(test_gen, steps=len(seqs_test))\n",
    "print('Loss:', H_evaluate[0])\n",
    "print('MAE:', H_evaluate[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
