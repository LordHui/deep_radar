{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import types\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.layers import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_embedding_model(hidden_1, hidden_2,\\\n",
    "                         num_layers=1, reshape=None):\n",
    "    global input_shape\n",
    "    model = Sequential()\n",
    "    if reshape:\n",
    "        model.add(Reshape(reshape, input_shape=input_shape))\n",
    "        model.add(LSTM(hidden_1, return_sequences=True))\n",
    "    else:\n",
    "        model.add(LSTM(hidden_1, return_sequences=True, input_shape=input_shape))\n",
    "    return model\n",
    "\n",
    "def lstm_counting_model(model, counting_hidden_1, counting_dense_1,\\\n",
    "                        counting_dense_2, kernel_initializer='normal',\\\n",
    "                        optimizer=None, learning_rate=0.001, dropout=None):\n",
    "    \n",
    "    if optimizer == 'adam' or optimizer is None:\n",
    "        optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        \n",
    "    #model.add(Masking(mask_value=0.0, name='mask'))\n",
    "    model.add(LSTM(counting_hidden_1, return_sequences=False, name='counting_lstm_1'))\n",
    "    #model.add(Dense(counting_dense_1, activation='relu', kernel_initializer=kernel_initializer, name='counting_dense_1'))\n",
    "    #model.add(Dense(counting_dense_2, activation='relu', kernel_initializer=kernel_initializer, name='counting_dense_2'))\n",
    "    model.add(Dense(1, name='output'))\n",
    "    model.add(Activation('softplus'))\n",
    "    model.compile(loss='poisson', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def build_lstm_time_model(hidden_1, hidden_2, counting_hidden_1,\\\n",
    "                          counting_dense_1, counting_dense_2,\\\n",
    "                          kernel_initializer='normal',\\\n",
    "                          learning_rate=1e-2, optimizer='adam', dropout=None):\n",
    "    \n",
    "    model = lstm_embedding_model(hidden_1, hidden_2, reshape=(-1, 2))\n",
    "    counting_model = lstm_counting_model(model, counting_hidden_1,\\\n",
    "                                         counting_dense_1, counting_dense_2,\\\n",
    "                                         kernel_initializer=kernel_initializer,\\\n",
    "                                         optimizer=optimizer, learning_rate=learning_rate, dropout=dropout)\n",
    "    return counting_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    data_type = 'time'\n",
    "    window = 256\n",
    "    loss = 'poisson'\n",
    "    model_type = 'lstm_time'\n",
    "    base_path = '/scratch/sk7898/pedbike/window_256'\n",
    "    batch_size = 64\n",
    "    scaling = False\n",
    "\n",
    "if data_type == 'stft':\n",
    "    fileloc = os.path.join(base_path, 'downstream_stft')\n",
    "elif data_type == 'time':\n",
    "    fileloc = os.path.join(base_path, 'downstream_time')\n",
    "else:\n",
    "    raise ValueError('Only stft/time are valid data types')\n",
    "    \n",
    "x_train, x_val, x_test, y_train, y_val, y_test, seqs_train, seqs_val, seqs_test = get_data(fileloc)\n",
    "n_bins = int(len(seqs_train)/batch_size)\n",
    "    \n",
    "assert x_train.shape[0] == y_train.shape[0] == seqs_train.shape[0]    \n",
    "\n",
    "n_timesteps, n_features = None, window*2\n",
    "input_shape=(n_timesteps, n_features)\n",
    "\n",
    "train_gen = train_generator(n_bins, x_train, y_train, seq_lengths=seqs_train, padding=True, padding_value=0.0)\n",
    "val_gen = val_generator(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scaling:\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_train_val = scaler.fit_transform(np.hstack((y_train, y_val)).reshape(-1, 1))\n",
    "    y_train = y_train_val[:len(y_train)]\n",
    "    y_val = y_train_val[len(y_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.3659 Epoch 00001: val_loss improved from inf to 1.02307, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20200102171937/best_val_loss_model.h5\n",
      "12/12 [==============================] - 94s 8s/step - loss: 1.3875 - val_loss: 1.0231\n",
      "Epoch 2/5\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.2535 Epoch 00002: val_loss improved from 1.02307 to 1.00525, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20200102171937/best_val_loss_model.h5\n",
      "12/12 [==============================] - 92s 8s/step - loss: 1.2570 - val_loss: 1.0053\n",
      "Epoch 3/5\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.1547 Epoch 00003: val_loss improved from 1.00525 to 1.00111, saving model to /scratch/sk7898/radar_counting/models/poisson/lstm_time/20200102171937/best_val_loss_model.h5\n",
      "12/12 [==============================] - 92s 8s/step - loss: 1.1616 - val_loss: 1.0011\n",
      "Epoch 4/5\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.1119 Epoch 00004: val_loss did not improve\n",
      "12/12 [==============================] - 92s 8s/step - loss: 1.1011 - val_loss: 1.0101\n",
      "Epoch 5/5\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 1.0341 Epoch 00005: val_loss did not improve\n",
      "12/12 [==============================] - 92s 8s/step - loss: 1.0453 - val_loss: 1.0215\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr = 1e-4\n",
    "optimizer = 'adam' #'adam', 'sgd'\n",
    "dropout = 0.2\n",
    "hidden_1 = 64\n",
    "hidden_2 = 32\n",
    "counting_hidden_1 = 32\n",
    "counting_dense_1 = 64\n",
    "counting_dense_2 = 16\n",
    "\n",
    "output_path = os.path.join('/scratch/sk7898/radar_counting/models/' + loss, model_type, datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "#Callbacks for the training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, min_delta=1e-4, verbose=5, mode='auto')\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)        \n",
    "model_checkpoint = ModelCheckpoint(os.path.join(output_path, 'best_val_loss_model.h5'),\\\n",
    "                                   monitor='val_loss', verbose=5, save_best_only=True, mode='auto')\n",
    "\n",
    "callbacks = [early_stopping, reduce_LR, model_checkpoint]\n",
    "        \n",
    "model = build_lstm_time_model(hidden_1, hidden_2, counting_hidden_1,\\\n",
    "                              counting_dense_1, counting_dense_2,\\\n",
    "                              learning_rate=lr, optimizer=optimizer, dropout=dropout)\n",
    "\n",
    "H_train = model.fit_generator(train_gen, validation_data=val_gen, validation_steps=1,\\\n",
    "                              steps_per_epoch=n_bins, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.121722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.121172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.121184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.122265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.120042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.121731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.116413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.121722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.121703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.120356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.120824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.122149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.122166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Prediction\n",
       "0      1.0    0.122180\n",
       "1      1.0    0.121822\n",
       "2      1.0    0.120417\n",
       "3      1.0    0.115429\n",
       "4      1.0    0.121717\n",
       "5      2.0    0.121722\n",
       "6      4.0    0.122152\n",
       "7      2.0    0.121172\n",
       "8      1.0    0.119199\n",
       "9      3.0    0.122149\n",
       "10     3.0    0.122149\n",
       "11     4.0    0.122145\n",
       "12     1.0    0.122325\n",
       "13     1.0    0.122156\n",
       "14     3.0    0.122149\n",
       "15     1.0    0.122031\n",
       "16     5.0    0.121184\n",
       "17     4.0    0.122149\n",
       "18     2.0    0.122149\n",
       "19     4.0    0.122149\n",
       "20     1.0    0.121719\n",
       "21     1.0    0.121459\n",
       "22     3.0    0.122149\n",
       "23     5.0    0.122265\n",
       "24     3.0    0.122149\n",
       "25     1.0    0.121808\n",
       "26     3.0    0.120042\n",
       "27     1.0    0.122061\n",
       "28     2.0    0.122041\n",
       "29     1.0    0.121720\n",
       "..     ...         ...\n",
       "66     2.0    0.122151\n",
       "67     1.0    0.121980\n",
       "68     1.0    0.122150\n",
       "69     4.0    0.122149\n",
       "70     1.0    0.115825\n",
       "71     1.0    0.119998\n",
       "72     2.0    0.122149\n",
       "73     2.0    0.121731\n",
       "74     2.0    0.122163\n",
       "75     2.0    0.116413\n",
       "76     5.0    0.121722\n",
       "77     3.0    0.122149\n",
       "78     2.0    0.121703\n",
       "79     3.0    0.120356\n",
       "80     1.0    0.121085\n",
       "81     4.0    0.122202\n",
       "82     1.0    0.122304\n",
       "83     4.0    0.122149\n",
       "84     1.0    0.119131\n",
       "85     2.0    0.122149\n",
       "86     1.0    0.119531\n",
       "87     2.0    0.122154\n",
       "88     3.0    0.122149\n",
       "89     3.0    0.122255\n",
       "90     2.0    0.122146\n",
       "91     2.0    0.122149\n",
       "92     2.0    0.120824\n",
       "93     6.0    0.122149\n",
       "94     1.0    0.120250\n",
       "95     2.0    0.122166\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted_train = model.predict_generator(train_gen, steps=int(len(seqs_train)/batch_size))\n",
    "#print('Predicted Train: ', predicted_train)\n",
    "test_gen = test_generator(x_test, y_test)\n",
    "test_score = model.predict_generator(test_gen, steps=len(seqs_test))\n",
    "\n",
    "if scaling:\n",
    "    test_score = scaler.inverse_transform(test_score.reshape(-1, 1))\n",
    "    \n",
    "df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})\n",
    "for i in range(len(x_test)):\n",
    "    df_result = df_result.append({'Actual': y_test[i], 'Prediction': test_score[i][0]}, ignore_index=True)\n",
    "    \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y_test.astype(np.int8), test_score_scl.astype(np.int8)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
